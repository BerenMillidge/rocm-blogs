<head>
  <meta charset="UTF-8">
  <meta name="description" content="AMD ROCm™ software blogs">
  <meta name="keywords" content="AMD GPU, MI300, MI250, ROCm, blog">
</head>

# AMD ROCm™ software blogs

::::{grid} 3
:margin: 1

:::{grid-item-card} LLM fine-tuning with JAX
:padding: 1
:link: ./artificial-intelligence/distributed-sft-jax/README
:link-type: doc

LLM distributed supervised fine-tuning with JAX
+++
26 Jan 2024
:::

:::{grid-item-card} Pre-training BERT (PyTorch)
:padding: 1
:link: ./artificial-intelligence/bert-hg-pytorch/README
:link-type: doc

Pre-training BERT using Hugging Face & PyTorch on multiple AMD GPUs
+++
26 Jan 2024
:::

:::{grid-item-card} Pre-training BERT (TensorFlow)
:padding: 1
:link: ./artificial-intelligence/bert-hg-tf/README
:link-type: doc

Pre-training BERT using Hugging Face & TensorFlow on a single AMD GPU
+++
26 Jan 2024
:::

:::{grid-item-card} Fine-tune Llama 2 with LoRA
:padding: 1
:link: ./artificial-intelligence/llama2-lora/README
:link-type: doc

A step-by-step guide to customizing a LLM for question answering
+++
26 Jan 2024
:::

:::{grid-item-card} LoRA & efficient fine-tuning
:padding: 1
:link: ./artificial-intelligence/lora-fundamentals/README
:link-type: doc

Using LoRA for efficient fine-tuning: fundamental principles
+++
26 Jan 2024
:::

:::{grid-item-card} LLM training with Megatron-DeepSpeed
:padding: 1
:link: ./artificial-intelligence/megatron-deepspeed-pretrain/README
:link-type: doc

Pre-training a large language model with Megatron-DeepSpeed on multiple AMD GPUs
+++
26 Jan 2024
:::

:::{grid-item-card} PyTorch Lightning
:padding: 1
:link: ./artificial-intelligence/pytorch-lightning/README
:link-type: doc

PyTorch Lightning on AMD GPUs
+++
26 Jan 2024
:::

:::{grid-item-card} Accelerating XGBoost
:padding: 1
:link: ./artificial-intelligence/xgboost-multi-gpu/README
:link-type: doc

Accelerating XGBoost using Multiple AMD GPUs
+++
26 Jan 2024
:::
::::
