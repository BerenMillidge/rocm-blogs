{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "405c3c33-e7b1-4674-8909-526f84de88f2",
   "metadata": {},
   "source": [
    "# Sentence Transformers on AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd519ed-7a42-4ec9-b1b7-79d198ac9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets ipywidgets -U transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118dc3d-131b-425e-9077-466fa0675d0e",
   "metadata": {},
   "source": [
    "# Building semantic search with Sentence-Transformers on AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1e975-c268-4c69-b5dc-b17b68a959f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import InputExample, util\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from sentence_transformers import losses\n",
    "from sentence_transformers import SentenceTransformer, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ed6e6-ec2b-4d62-9998-ce90f533f0d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.- Define the custom model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2e6d9-e127-4235-9d77-529780c1de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom model\n",
    "# Use an existing embedding model\n",
    "word_embedding_model = models.Transformer('bert-base-uncased', max_seq_length=256)\n",
    "\n",
    "# Pool function over the token embeddings\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "# Dense function\n",
    "dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), out_features=256, activation_function=nn.Tanh())\n",
    "\n",
    "# Define the overall model\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee33d86-7fb2-488d-bc77-83c32f76031e",
   "metadata": {},
   "source": [
    "## 2.- Sentence Compression Dataset for training\n",
    "* Language: English\n",
    "* Number of records 180 000\n",
    "* Dataset with pairs of equivalent sentences.Large corpus of uncompressed and compressed sentences from news articles. \n",
    "* Useful for semantic search and sentence similarity.\n",
    "* Dataset structure:\n",
    "    * {\"set\": [sentence_1, sentence_2]}\n",
    "    * {\"set\": [sentence_1, sentence_2]}\n",
    "    * ...\n",
    "    * {\"set\": [sentence_1, sentence_2]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21fd809-3430-443d-9c48-1804e360fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"embedding-data/sentence-compression\"\n",
    "dataset = load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09bb65-ea61-40f8-a433-f357e7b811db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore one sample\n",
    "dataset['train']['set'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215bde86-d888-4f8e-9e97-537d2decc2e0",
   "metadata": {},
   "source": [
    "### 2.1.- Transform dataset into required format for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d1ebb-3b28-46b0-93ab-a148fd934ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataset in required format\n",
    "train_examples = []\n",
    "train_data = dataset['train']['set']\n",
    "\n",
    "n_examples = dataset['train'].num_rows//2 #select half of the dataset for training\n",
    "\n",
    "for example in train_data[:n_examples]:\n",
    "    original_sentence = example[0]\n",
    "    compressed_sentence = example[1]\n",
    "    \n",
    "    input_example = InputExample(texts = [original_sentence, compressed_sentence])\n",
    "    \n",
    "    train_examples.append(input_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0e581-0a07-4fff-996e-f1c5d19c031d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a55fd9-c88a-4b6f-928b-601b4bbd1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Dataloader with training examples\n",
    "train_dataloader = DataLoader(train_examples, shuffle = True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b4ef6-d21c-4c17-9f6e-99ac4d7b43c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8db72b7b-8c48-417c-8bd9-82cd1433601d",
   "metadata": {},
   "source": [
    "## 3.- Select loss function & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dab50f-57d1-4282-a14e-fcac632da7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Given the dataset of equivalent sentences, choose MultipleNegativesRankingLoss\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model = model)\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1965f8-cfe9-44ba-a0ac-2130086d2e21",
   "metadata": {},
   "source": [
    "## 4.- Test the model for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f3c6e2-35f6-4adb-9906-1a71490c4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Sentences (documents/corpus) to encode\n",
    "sentences = [\n",
    "    'Paris, which is a city in Europe with traditions and remarkable food, is the capital of France',\n",
    "    'The capital of France is Paris',\n",
    "    'Australia is known for its traditions and remarkable food',\n",
    "    \"\"\"\n",
    "        Despite the heavy rains that lasted for most of the week, the outdoor music festival, \n",
    "        which featured several renowned international artists, was able to proceed as scheduled, \n",
    "        much to the delight of fans who had traveled from all over the country\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "        Photosynthesis, a process used by plans and other organisms to convert light into\n",
    "        chemical energy, plays a crucial role in maintaining the balance of oxygen and carbon\n",
    "        dioxide in the Earth's atmosphere.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Enconde the sentences\n",
    "sentences_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['Is Paris located in France?', 'Tell me something about Australia', \n",
    "           'music festival proceeding despite heavy rains',\n",
    "           'what is the process that some organisms use to transform light into chemical energy?']\n",
    "\n",
    "\n",
    "# Find the closest sentences of the corpus for each query using cosine similarity\n",
    "for query in queries:\n",
    "    \n",
    "    # Enconde the current query\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # Cosine-similarity and closest document to query\n",
    "    cos_scores = util.cos_sim(query_embedding, sentences_embeddings)[0]\n",
    "    \n",
    "    top_results = torch.argsort(cos_scores, descending = True)\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nSimilar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results:\n",
    "        print(sentences[idx], \"(Score: {:.4f})\".format(cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b8e1b6-b165-4d66-a84c-7bcdcd9b586b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffadd10a-3ad6-41ba-aab9-677f147d1df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
