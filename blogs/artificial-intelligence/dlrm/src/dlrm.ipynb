{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rocm-smi --showproductname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! apt show rocm-core -a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"number of GPUs: {torch.cuda.device_count()}\")\n",
    "print([torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (24.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip\n",
    "! pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from scikit-learn) (1.23.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_epochs = 10\n",
    "lr = 3e-4\n",
    "batch_size = 128\n",
    "hidden_size = 32\n",
    "embd_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"label\", *(f\"I{i}\" for i in range(1, 14)), *(f\"C{i}\" for i in range(1, 27))]\n",
    "df = pd.read_csv(\n",
    "    \"../data/dac_sample.txt\", sep=\"\\t\", names=columns\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "sparse_cols = [\"C\" + str(i) for i in range(1, 27)]\n",
    "dense_cols = [\"I\" + str(i) for i in range(1, 14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[sparse_cols + dense_cols]\n",
    "data = data.astype(str)\n",
    "for feat in sparse_cols:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_cols] = mms.fit_transform(data[dense_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C1   C2     C3     C4   C5  C6    C7  C8  C9   C10  ...        I4  \\\n",
      "17040    8  130   7703   6127   23  10  4116  48   2  7709  ...  0.014388   \n",
      "76247  300   17  17693   9570   23   5  3896  86   2  2505  ...  0.023981   \n",
      "77532  195  428  20608  20653   23   0  1923  86   2    62  ...  0.000000   \n",
      "8959   283  126      0      0  103   5  2124   8   2  3178  ...  0.000000   \n",
      "18872  250   21  29261  13191   23   0  3686   8   0  2505  ...  0.004796   \n",
      "\n",
      "             I5        I6        I7        I8        I9       I10       I11  \\\n",
      "17040  0.000009  0.000368  0.000114  0.001283  0.000474  0.166667  0.009615   \n",
      "76247  0.002769  0.014487  0.000227  0.004704  0.007898  0.000000  0.009615   \n",
      "77532  0.000136  0.000000  0.000000  0.000214  0.000079  0.000000  0.000000   \n",
      "8959   0.017018  0.004911  0.000227  0.000000  0.003791  0.000000  0.009615   \n",
      "18872  0.018101  0.000000  0.000000  0.002780  0.013506  0.000000  0.000000   \n",
      "\n",
      "       I12       I13  \n",
      "17040  0.0  0.000915  \n",
      "76247  0.0  0.001525  \n",
      "77532  0.0  0.000000  \n",
      "8959   0.0  0.000000  \n",
      "18872  0.0  0.000305  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of categories for each categorical feature\n",
    "num_categories = [len(data[c].unique()) for c in sparse_cols]\n",
    "\n",
    "# Only keep categorical features with less than 10K categories\n",
    "indices_to_keep = [i for i, num in enumerate(num_categories) if num <= 10000]\n",
    "num_categories_kept = [num_categories[i] for i in indices_to_keep]\n",
    "sparse_cols_kept = [sparse_cols[i] for i in indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, df[\"label\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "# train\n",
    "X_train_sparse = torch.tensor(X_train[sparse_cols_kept].values, dtype=torch.long).to(\n",
    "    device\n",
    ")\n",
    "X_train_dense = torch.tensor(X_train[dense_cols].values, dtype=torch.float).to(device)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float).unsqueeze(1).to(device)\n",
    "\n",
    "# test\n",
    "X_test_sparse = torch.tensor(X_test[sparse_cols_kept].values, dtype=torch.long).to(device)\n",
    "X_test_dense = torch.tensor(X_test[dense_cols].values, dtype=torch.float).to(device)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float).unsqueeze(1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_sparse, X_train_dense, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Create DataLoader for test data\n",
    "test_dataset = TensorDataset(X_test_sparse, X_test_dense, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureInteraction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureInteraction, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_dim = x.shape[1]\n",
    "\n",
    "        concat_features = x.view(-1, feature_dim, 1)\n",
    "        dot_products = torch.matmul(concat_features, concat_features.transpose(1, 2))\n",
    "        ones = torch.ones_like(dot_products)\n",
    "\n",
    "        mask = torch.triu(ones)\n",
    "        out_dim = feature_dim * (feature_dim + 1) // 2\n",
    "\n",
    "        flat_result = dot_products[mask.bool()]\n",
    "        reshape_result = flat_result.view(-1, out_dim)\n",
    "\n",
    "        return reshape_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLRM(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embd_dim,\n",
    "        num_categories,\n",
    "        num_dense_feature,\n",
    "        hidden_size,\n",
    "    ):\n",
    "        super(DLRM, self).__init__()\n",
    "        # create embedding for each categorical feature with the same embedding dimension\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(num_cat, embd_dim) for num_cat in num_categories]\n",
    "        )\n",
    "\n",
    "        self.feat_interaction = FeatureInteraction()\n",
    "        self.bottom_mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=num_dense_feature, out_features=hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, embd_dim),\n",
    "        )\n",
    "        num_feat = (\n",
    "            len(num_categories) * embd_dim + embd_dim\n",
    "        )  # categorical and dense features\n",
    "        num_feat_interact = num_feat * (num_feat + 1) // 2  # interaction features\n",
    "        top_mlp_in = (\n",
    "            num_feat_interact + embd_dim\n",
    "        )  # interaction concat with dense features\n",
    "        self.top_mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=top_mlp_in, out_features=hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        B = x_cat.shape[0]\n",
    "        num_sparse_feat = x_cat.shape[1]\n",
    "\n",
    "        # look up embedding for categorical features\n",
    "        embed_x = torch.concat(\n",
    "            [\n",
    "                self.embeddings[i](x_cat[:, i]).unsqueeze(1)\n",
    "                for i in range(num_sparse_feat)\n",
    "            ]\n",
    "        )  # B, num_sparse_feat, embedding dim\n",
    "        embed_x = embed_x.view(B, -1)  # B, num_sparse_feat * embedding dim\n",
    "\n",
    "        # get bottom dense features\n",
    "        dense_x = self.bottom_mlp(x_num)  # B, embedding dim\n",
    "        # concatenate with embeddings\n",
    "        x = torch.concat(\n",
    "            [embed_x, dense_x], dim=-1\n",
    "        )  # B, (num_sparse_feat+1) * embedding dim\n",
    "        # get 2nd order interaction features\n",
    "        x = self.feat_interaction(x)  # B, n*(n+1) // 2\n",
    "        # combine with dense features\n",
    "        x = torch.concat([x, dense_x], dim=-1)\n",
    "        # pass through top mlp\n",
    "        x = self.top_mlp(x)  # B, 1\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Define the model, loss function and optimizer\n",
    "model = DLRM(\n",
    "    embd_dim=embd_dim,\n",
    "    num_categories=num_categories_kept,\n",
    "    num_dense_feature=len(dense_cols),\n",
    "    hidden_size=hidden_size,\n",
    ")\n",
    "model.to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cuda\n",
      "2.195553 M parameters\n",
      "DLRM(\n",
      "  (embeddings): ModuleList(\n",
      "    (0): Embedding(541, 16)\n",
      "    (1): Embedding(497, 16)\n",
      "    (2): Embedding(145, 16)\n",
      "    (3): Embedding(12, 16)\n",
      "    (4): Embedding(7623, 16)\n",
      "    (5): Embedding(257, 16)\n",
      "    (6): Embedding(3, 16)\n",
      "    (7): Embedding(3799, 16)\n",
      "    (8): Embedding(2796, 16)\n",
      "    (9): Embedding(26, 16)\n",
      "    (10): Embedding(5238, 16)\n",
      "    (11): Embedding(10, 16)\n",
      "    (12): Embedding(2548, 16)\n",
      "    (13): Embedding(1303, 16)\n",
      "    (14): Embedding(4, 16)\n",
      "    (15): Embedding(11, 16)\n",
      "    (16): Embedding(14, 16)\n",
      "    (17): Embedding(51, 16)\n",
      "    (18): Embedding(9527, 16)\n",
      "  )\n",
      "  (feat_interaction): FeatureInteraction()\n",
      "  (bottom_mlp): Sequential(\n",
      "    (0): Linear(in_features=13, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  )\n",
      "  (top_mlp): Sequential(\n",
      "    (0): Linear(in_features=51376, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f\"running on {device}\")\n",
    "print(sum(p.numel() for p in model.parameters()) / 1e6, \"M parameters\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    for i, (x_sparse, x_dense, y) in enumerate(tqdm(train_loader)):\n",
    "        x_sparse = x_sparse.to(device)\n",
    "        x_dense = x_dense.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_sparse, x_dense)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, dataname):\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x_sparse, x_dense, y) in enumerate(tqdm(dataloader)):\n",
    "            x_sparse = x_sparse.to(device)\n",
    "            x_dense = x_dense.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x_sparse, x_dense)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            predictions = (probs > 0.5).long()\n",
    "\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * y.shape[0]\n",
    "            total_correct += (predictions == y).sum().item()\n",
    "            total_samples += y.shape[0]\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples * 100\n",
    "    print(\n",
    "        f\"{dataname} accuracy = {accuracy:0.2f}%, {dataname} avg loss = {avg_loss:.6f}\"\n",
    "    )\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 81.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 326.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.33%, train avg loss = 0.527628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 329.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.05%, test avg loss = 0.531474\n",
      "\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 87.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 322.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.35%, train avg loss = 0.510776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 324.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.15%, test avg loss = 0.513944\n",
      "\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 85.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 324.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.37%, train avg loss = 0.505342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 326.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.16%, test avg loss = 0.508535\n",
      "\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 87.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 325.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.37%, train avg loss = 0.503098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 326.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.19%, test avg loss = 0.506277\n",
      "\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 87.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 324.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.38%, train avg loss = 0.500283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 326.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.23%, test avg loss = 0.504150\n",
      "\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 87.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 324.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.42%, train avg loss = 0.500728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 326.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.18%, test avg loss = 0.503704\n",
      "\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 87.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 322.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.40%, train avg loss = 0.500489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 324.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.16%, test avg loss = 0.504549\n",
      "\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 87.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 323.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.36%, train avg loss = 0.498717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 323.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.10%, test avg loss = 0.502005\n",
      "\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 87.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 322.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.38%, train avg loss = 0.497998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 327.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.14%, test avg loss = 0.501504\n",
      "\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:07<00:00, 87.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 322.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 77.42%, train avg loss = 0.497777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 326.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 77.06%, test avg loss = 0.501636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"epoch {epoch+1}\")\n",
    "    train_one_epoch()\n",
    "    evaluate(train_loader, \"train\")\n",
    "    evaluate(test_loader, \"test\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we use the first 10 rows of the dataset as ad candidates\n",
    "num_ads = 10\n",
    "df_c = pd.DataFrame(data.iloc[0:num_ads])\n",
    "# get the ad candidate features\n",
    "df_ads = df_c[df_c.columns[26:39]]\n",
    "# get the user features of the first row\n",
    "df_user = df_c[df_c.columns[0:26]].iloc[0:1]\n",
    "# replicate the user feature across all ad candidate rows\n",
    "df_user_rep = df_user\n",
    "for i in range(num_ads-1): \n",
    "    df_user_rep = pd.concat([df_user_rep, df_user], ignore_index=True, sort=False)\n",
    "df_candidates = pd.concat([df_user_rep, df_ads], axis=1)\n",
    "\n",
    "# Convert the feature vectors to tensor\n",
    "X_inf_sparse = torch.tensor(df_candidates[sparse_cols_kept].values, dtype=torch.long).to(device)\n",
    "X_inf_dense = torch.tensor(df_candidates[dense_cols].values, dtype=torch.float).to(device)\n",
    "\n",
    "# create data loader for inferencing\n",
    "y_dummy = torch.tensor([0]*num_ads, dtype=torch.float).unsqueeze(1).to(device)\n",
    "inf_dataset = TensorDataset(X_inf_sparse, X_inf_dense, y_dummy)\n",
    "inf_loader = DataLoader(inf_dataset, batch_size=num_ads, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend():\n",
    "    with torch.no_grad():\n",
    "        for i, (x_sparse, x_dense, y) in enumerate(tqdm(inf_loader)):\n",
    "            x_sparse = x_sparse.to(device)\n",
    "            x_dense = x_dense.to(device)\n",
    "            logits = model(x_sparse, x_dense)\n",
    "            probs = torch.sigmoid(logits)\n",
    "    print(probs)\n",
    "    return torch.max(probs, dim=0).indices[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 315.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1380],\n",
      "        [0.2414],\n",
      "        [0.3493],\n",
      "        [0.3500],\n",
      "        [0.1807],\n",
      "        [0.3009],\n",
      "        [0.2203],\n",
      "        [0.3639],\n",
      "        [0.1890],\n",
      "        [0.3702]], device='cuda:0')\n",
      "Best ad candidate is ad 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Best ad candidate is ad', recommend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
