{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Huggingface Unconditional generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import MusicgenForConditionalGeneration\n",
        "\n",
        "# initialize model and model's input\n",
        "model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "unconditional_inputs = model.get_unconditional_inputs(num_samples=1)\n",
        "\n",
        "# generate audio\n",
        "audio_values = model.generate(**unconditional_inputs, do_sample=True, max_new_tokens=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "sampling_rate = model.config.audio_encoder.sampling_rate\n",
        "\n",
        "# listen to our audio sample\n",
        "Audio(audio_values[0].cpu(), rate=sampling_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Huggingface Text-conditional generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "\n",
        "# initialize model\n",
        "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
        "model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "\n",
        "# set device to GPU\n",
        "device = 'cuda'\n",
        "model = model.to(device)\n",
        "\n",
        "# our text description for the model\n",
        "input_text = [\"epic movie theme\", \"sad jazz\"]\n",
        "\n",
        "# create input\n",
        "inputs = processor(\n",
        "    text=input_text,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(device)\n",
        "\n",
        "# generate audio\n",
        "audio_values_from_text = model.generate(**inputs, max_new_tokens=512)\n",
        "\n",
        "print(audio_values_from_text.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "sampling_rate = model.config.audio_encoder.sampling_rate\n",
        "\n",
        "# listen to our first audio sample from input text \"epic music theme\"\n",
        "Audio(audio_values_from_text[0].cpu(), rate=sampling_rate)\n",
        "\n",
        "# listen to our second audio sample from input text \"sad jazz\"\n",
        "Audio(audio_values_from_text[1].cpu(), rate=sampling_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Huggingface Audio-prompted generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# take the first half of the generated audio\n",
        "sample = audio_values_from_text[1][0].cpu().numpy()\n",
        "sample = sample[: len(sample) // 2]\n",
        "\n",
        "# use it as input\n",
        "inputs = processor(\n",
        "    audio=sample,\n",
        "    sampling_rate=sampling_rate,\n",
        "    text=[\"sad jazz\"],\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(device)\n",
        "audio_values = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Audio(audio_values[0].cpu(), rate=sampling_rate)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
