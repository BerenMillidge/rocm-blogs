{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Llama 2 with LoRA: Customizing a large language model for question-answering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** {ref}Sean Song <sean-song>, AI Software Solutions\\\n",
    "**Read time:** 10 minutes\\\n",
    "**Last edited:** 4 Jan 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog, we show you how to fine-tune Llama 2 on an AMD GPU with ROCm. We use Low-Rank Adaptation of Large Language Models (LoRA) to overcome memory and computing limitations and make open-source large language models (LLMs) more accessible. We also show you how to fine-tune and upload models to Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Introduction<a class=\"anchor\" id=\"Introduction\"></a>\n",
    "In the dynamic realm of Generative AI (GenAI), fine-tuning LLMs (such as Llama 2) poses distinctive challenges related to substantial computational and memory requirements. LoRA introduces a compelling solution, allowing rapid and cost-effective fine-tuning of state-of-the-art LLMs. This breakthrough capability not only expedites the tuning process, but also lowers associated costs.\n",
    "\n",
    "To explore the benefits of LoRA, we provide a comprehensive walkthrough of the fine-tuning process for Llama 2 using LoRA specifically tailored for question-answering (QA) tasks on an AMD GPU.\n",
    "\n",
    "Before jumping in, let's take a moment to briefly review the three pivotal components that form the foundation of our discussion:\n",
    "\n",
    "- Llama 2: Meta's advanced language model with variants that scale up to 70 billion parameters.\n",
    "- Fine-tuning: A crucial process that refines LLMs for specialized tasks, optimizing its performance.\n",
    "- LoRA: The algorithm employed for fine-tuning Llama 2, ensuring effective adaptation to specialized tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 2<a class=\"anchor\" id=\"Understanding_Llama_2\"></a>\n",
    "[Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288) is a collection of second-generation, open-source LLMs from Meta; it comes with a commercial license. Llama 2 is designed to handle a wide range of natural language processing (NLP) tasks, with models ranging in scale from 7 billion to 70 billion parameters.\n",
    "\n",
    "Llama 2 Chat, which is optimized for dialogue, has shown similar performance to popular closed-source models like ChatGPT and PaLM. You can improve the performance of this model by fine-tuning it with a high-quality conversational data set. In this blog post, we delve into the process of refining a Llama 2 Chat model using a QA data set.\n",
    "\n",
    "### Fine-tuning a model<a class=\"anchor\" id=\"Model_Fine_Tuning\"></a>\n",
    "Fine-tuning in machine learning is the process of adjusting the weights and parameters of a pre-trained model using new data in order to improve its performance on a specific task. It involves using a new data set--one that is specific to the current task--to update the model's weights. It's typically not possible to fine-tune LLMs on consumer hardware due to inadequate memory and computing power. However, in this tutorial, we use LoRA to overcome these challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA<a class=\"anchor\" id=\"Lora\"></a>\n",
    "[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) is an innovative technique-- developed by researchers at Microsoft--designed to address the challenges of fine-tuning LLMs. This results in a significant reduction in the number of parameters (by a factor of up to 10,000) that need to be fine-tuned, which significantly reduces GPU memory requirements. To learn more about the fundamental principles of LoRA, refer to [Using LoRA for efficient fine-tuning: Fundamental principles](../lora-fundamentals/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step-by-step Llama 2 fine-tuning<a class=\"anchor\" id=\"Step-By-Step-Guide\"></a>\n",
    "Standard (full-parameter) fine-tuning involves considering all parameters. It requires significant computational power to manage optimizer states and gradient check-pointing. The resulting memory footprint is typically about four times larger than the model itself. For example, loading a 7 billion parameter model (e.g. Llama 2) in FP32 (4 bytes per parameter) requires approximately 28 GB of GPU memory, while fine-tuning demands around 28*4=112 GB of GPU memory. Note that the 112 GB figure is derived empirically, and various factors like batch size, data precision, and gradient accumulation contribute to overall memory usage.\n",
    "\n",
    "To overcome this memory limitation, you can use a parameter-efficient fine-tuning (PEFT) technique, such as LoRA.\n",
    "\n",
    "This example leverages two GCDs (Graphics Compute Dies) of a AMD MI250 GPU and each GCD are equipped with 64 GB of VRAM. Using this setup allows us to explore different settings for fine-tuning the Llama 2–7b weights with and without LoRA.\n",
    "\n",
    "Our setup:\n",
    "- Hardware: AMD Instinct MI250\n",
    "- Software: [ROCm 5.7.1](https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html)\n",
    "- Libraries: transformers, accelerate, peft, trl, and bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's confirm the availability of the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rocm-smi --showproductname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "========================= ROCm System Management Interface =========================\n",
    "=================================== Product Info ===================================\n",
    "GPU[0]\t\t: Card series: \t\tAMD INSTINCT MI250 (MCM) OAM AC MBA\n",
    "GPU[0]\t\t: Card model: \t\t0x0b0c\n",
    "GPU[0]\t\t: Card vendor: \t\tAdvanced Micro Devices, Inc. [AMD/ATI]\n",
    "GPU[0]\t\t: Card SKU: \t\tD65209\n",
    "GPU[1]\t\t: Card series: \t\tAMD INSTINCT MI250 (MCM) OAM AC MBA\n",
    "GPU[1]\t\t: Card model: \t\t0x0b0c\n",
    "GPU[1]\t\t: Card vendor: \t\tAdvanced Micro Devices, Inc. [AMD/ATI]\n",
    "GPU[1]\t\t: Card SKU: \t\tD65209\n",
    "====================================================================================\n",
    "=============================== End of ROCm SMI Log ================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, install the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas torch peft transformers==4.31.0 trl==0.4.7 accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing bitsandbytes\n",
    "ROCm needs a special version of bitsandbytes (bitsandbytes-rocm).\n",
    "1. Install bitsandbytes using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'bitsandbytes-rocm' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENVIRONMENT\n",
      "============================\n",
      "CUDA_VERSION: \n",
      "============================\n",
      "NVCC path: /bin/nvcc\n",
      "HIPCC path: /opt/rocm/bin/hipcc\n",
      "GPP path: /usr/bin/g++ VERSION: g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "CUDA_HOME: \n",
      "HIP_HOME: \n",
      "CONDA_PREFIX: \n",
      "PATH: /root/libexec/perf-core:/mnt:/opt/ompi/bin:/opt/ucx/bin:/opt/cache/bin:/opt/rocm/llvm/bin:/opt/rocm/opencl/bin:/opt/rocm/hip/bin:/opt/rocm/hcc/bin:/opt/rocm/bin:/opt/conda/envs/py_3.10/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "LD_LIBRARY_PATH: /opt/ompi/lib:/opt/rocm/lib:/usr/local/lib:\n",
      "============================\n",
      "/opt/rocm/bin/hipcc -std=c++14 -fPIC -c -DNO_HIPBLASLT -I /opt/rocm/include -I /home/aac/bitsandbytes-rocm/csrc -I /include -I /home/aac/bitsandbytes-rocm/include -L /opt/rocm/lib -lhipblas -lhiprand -lhipsparse -L /lib /home/aac/bitsandbytes-rocm/csrc/ops.hip -o /home/aac/bitsandbytes-rocm/build/ops.o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang++: warning: -lhipblas: 'linker' input unused [-Wunused-command-line-argument]\n",
      "clang++: warning: -lhiprand: 'linker' input unused [-Wunused-command-line-argument]\n",
      "clang++: warning: -lhipsparse: 'linker' input unused [-Wunused-command-line-argument]\n",
      "In file included from /home/aac/bitsandbytes-rocm/csrc/ops.hip:17:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/BinSearch.h:11:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/Algo-Direct2.h:3:\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]\n",
      "                myassert(Gap==1, \"if Gap>1 then X workspace must be provided\");\n",
      "                ^           ~~\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^~~~~\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses after the '!' to evaluate the comparison first\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses around left hand side expression to silence this warning\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "1 warning generated when compiling for gfx1030.\n",
      "In file included from /home/aac/bitsandbytes-rocm/csrc/ops.hip:17:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/BinSearch.h:11:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/Algo-Direct2.h:3:\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]\n",
      "                myassert(Gap==1, \"if Gap>1 then X workspace must be provided\");\n",
      "                ^           ~~\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^~~~~\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses after the '!' to evaluate the comparison first\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses around left hand side expression to silence this warning\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "1 warning generated when compiling for gfx1100.\n",
      "In file included from /home/aac/bitsandbytes-rocm/csrc/ops.hip:17:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/BinSearch.h:11:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/Algo-Direct2.h:3:\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]\n",
      "                myassert(Gap==1, \"if Gap>1 then X workspace must be provided\");\n",
      "                ^           ~~\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^~~~~\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses after the '!' to evaluate the comparison first\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses around left hand side expression to silence this warning\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "1 warning generated when compiling for gfx1101.\n",
      "In file included from /home/aac/bitsandbytes-rocm/csrc/ops.hip:17:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/BinSearch.h:11:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/Algo-Direct2.h:3:\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]\n",
      "                myassert(Gap==1, \"if Gap>1 then X workspace must be provided\");\n",
      "                ^           ~~\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^~~~~\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses after the '!' to evaluate the comparison first\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses around left hand side expression to silence this warning\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "1 warning generated when compiling for gfx900.\n",
      "In file included from /home/aac/bitsandbytes-rocm/csrc/ops.hip:17:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/BinSearch.h:11:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/Algo-Direct2.h:3:\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]\n",
      "                myassert(Gap==1, \"if Gap>1 then X workspace must be provided\");\n",
      "                ^           ~~\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^~~~~\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses after the '!' to evaluate the comparison first\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses around left hand side expression to silence this warning\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "1 warning generated when compiling for gfx906.\n",
      "In file included from /home/aac/bitsandbytes-rocm/csrc/ops.hip:17:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/BinSearch.h:11:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/Algo-Direct2.h:3:\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]\n",
      "                myassert(Gap==1, \"if Gap>1 then X workspace must be provided\");\n",
      "                ^           ~~\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^~~~~\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses after the '!' to evaluate the comparison first\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses around left hand side expression to silence this warning\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "1 warning generated when compiling for gfx908.\n",
      "In file included from /home/aac/bitsandbytes-rocm/csrc/ops.hip:17:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/BinSearch.h:11:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/Algo-Direct2.h:3:\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]\n",
      "                myassert(Gap==1, \"if Gap>1 then X workspace must be provided\");\n",
      "                ^           ~~\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^~~~~\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses after the '!' to evaluate the comparison first\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses around left hand side expression to silence this warning\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "1 warning generated when compiling for gfx90a.\n",
      "In file included from /home/aac/bitsandbytes-rocm/csrc/ops.hip:17:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/BinSearch.h:11:\n",
      "In file included from /home/aac/bitsandbytes-rocm/include/Algo-Direct2.h:3:\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]\n",
      "                myassert(Gap==1, \"if Gap>1 then X workspace must be provided\");\n",
      "                ^           ~~\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^~~~~\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses after the '!' to evaluate the comparison first\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "/home/aac/bitsandbytes-rocm/include/Algo-Direct-Common.h:193:17: note: add parentheses around left hand side expression to silence this warning\n",
      "/home/aac/bitsandbytes-rocm/include/Portable.h:53:33: note: expanded from macro 'myassert'\n",
      "#define myassert(cond, msg) if (!cond){ std::ostringstream os; os << \"\\nassertion failed: \" << #cond << \", \" << msg << \"\\n\"; throw std::invalid_argument(os.str()); }\n",
      "                                ^\n",
      "1 warning generated when compiling for host.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/rocm/bin/hipcc -std=c++14 -fPIC -c -DNO_HIPBLASLT -I /opt/rocm/include -I /home/aac/bitsandbytes-rocm/csrc -I /include -I /home/aac/bitsandbytes-rocm/include -L /opt/rocm/lib -lhipblas -lhiprand -lhipsparse -L /lib /home/aac/bitsandbytes-rocm/csrc/kernels.hip -o /home/aac/bitsandbytes-rocm/build/kernels.o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang++: warning: -lhipblas: 'linker' input unused [-Wunused-command-line-argument]\n",
      "clang++: warning: -lhiprand: 'linker' input unused [-Wunused-command-line-argument]\n",
      "clang++: warning: -lhipsparse: 'linker' input unused [-Wunused-command-line-argument]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "__global__ void kspmm_coo_very_sparse_naive(int *max_count, int *max_idx, int *offset_rowidx, int *rowidx, int *colidx, half *values, T *B, half *out, float * __restrict__ const dequant_stats, int nnz, int rowsA, int rowsB, int colsB)\n",
      "                ^\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "6 warnings generated when compiling for gfx1030.\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "__global__ void kspmm_coo_very_sparse_naive(int *max_count, int *max_idx, int *offset_rowidx, int *rowidx, int *colidx, half *values, T *B, half *out, float * __restrict__ const dequant_stats, int nnz, int rowsA, int rowsB, int colsB)\n",
      "                ^\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "6 warnings generated when compiling for gfx1100.\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "__global__ void kspmm_coo_very_sparse_naive(int *max_count, int *max_idx, int *offset_rowidx, int *rowidx, int *colidx, half *values, T *B, half *out, float * __restrict__ const dequant_stats, int nnz, int rowsA, int rowsB, int colsB)\n",
      "                ^\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "6 warnings generated when compiling for gfx1101.\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "__global__ void kspmm_coo_very_sparse_naive(int *max_count, int *max_idx, int *offset_rowidx, int *rowidx, int *colidx, half *values, T *B, half *out, float * __restrict__ const dequant_stats, int nnz, int rowsA, int rowsB, int colsB)\n",
      "                ^\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "6 warnings generated when compiling for gfx900.\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "__global__ void kspmm_coo_very_sparse_naive(int *max_count, int *max_idx, int *offset_rowidx, int *rowidx, int *colidx, half *values, T *B, half *out, float * __restrict__ const dequant_stats, int nnz, int rowsA, int rowsB, int colsB)\n",
      "                ^\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "6 warnings generated when compiling for gfx906.\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "__global__ void kspmm_coo_very_sparse_naive(int *max_count, int *max_idx, int *offset_rowidx, int *rowidx, int *colidx, half *values, T *B, half *out, float * __restrict__ const dequant_stats, int nnz, int rowsA, int rowsB, int colsB)\n",
      "                ^\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "6 warnings generated when compiling for gfx908.\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "__global__ void kspmm_coo_very_sparse_naive(int *max_count, int *max_idx, int *offset_rowidx, int *rowidx, int *colidx, half *values, T *B, half *out, float * __restrict__ const dequant_stats, int nnz, int rowsA, int rowsB, int colsB)\n",
      "                ^\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "/home/aac/bitsandbytes-rocm/csrc/kernels.hip:2822:17: warning: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n",
      "6 warnings generated when compiling for gfx90a.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/g++ -std=c++14 -D__HIP_PLATFORM_AMD__ -DBUILD_HIP -DNO_HIPBLASLT -shared -fPIC -I /opt/rocm/include -I /home/aac/bitsandbytes-rocm/csrc -I /include -I /home/aac/bitsandbytes-rocm/include /home/aac/bitsandbytes-rocm/build/ops.o /home/aac/bitsandbytes-rocm/build/kernels.o /home/aac/bitsandbytes-rocm/csrc/common.cpp /home/aac/bitsandbytes-rocm/csrc/cpu_ops.cpp /home/aac/bitsandbytes-rocm/csrc/pythonInterface.c -o ./bitsandbytes/libbitsandbytes_hip_nohipblaslt.so -L /opt/rocm/lib -lhipblas -lhiprand -lhipsparse -L /lib\n",
      "libs: ['libbitsandbytes_hip_nohipblaslt.so']\n",
      "running install\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_egg\n",
      "running egg_info\n",
      "writing bitsandbytes.egg-info/PKG-INFO\n",
      "writing dependency_links to bitsandbytes.egg-info/dependency_links.txt\n",
      "writing top-level names to bitsandbytes.egg-info/top_level.txt\n",
      "reading manifest file 'bitsandbytes.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'NOTICE.md'\n",
      "writing manifest file 'bitsandbytes.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying bitsandbytes/__init__.py -> build/lib/bitsandbytes\n",
      "copying bitsandbytes/__main__.py -> build/lib/bitsandbytes\n",
      "copying bitsandbytes/archive_functional.py -> build/lib/bitsandbytes\n",
      "copying bitsandbytes/cextension.py -> build/lib/bitsandbytes\n",
      "copying bitsandbytes/functional.py -> build/lib/bitsandbytes\n",
      "copying bitsandbytes/utils.py -> build/lib/bitsandbytes\n",
      "copying bitsandbytes/autograd/__init__.py -> build/lib/bitsandbytes/autograd\n",
      "copying bitsandbytes/autograd/_functions.py -> build/lib/bitsandbytes/autograd\n",
      "copying bitsandbytes/cuda_setup/__init__.py -> build/lib/bitsandbytes/cuda_setup\n",
      "copying bitsandbytes/cuda_setup/env_vars.py -> build/lib/bitsandbytes/cuda_setup\n",
      "copying bitsandbytes/cuda_setup/main.py -> build/lib/bitsandbytes/cuda_setup\n",
      "copying bitsandbytes/nn/__init__.py -> build/lib/bitsandbytes/nn\n",
      "copying bitsandbytes/nn/modules.py -> build/lib/bitsandbytes/nn\n",
      "copying bitsandbytes/nn/triton_based_modules.py -> build/lib/bitsandbytes/nn\n",
      "copying bitsandbytes/optim/__init__.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/optim/adagrad.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/optim/adam.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/optim/adamw.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/optim/lamb.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/optim/lars.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/optim/lion.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/optim/optimizer.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/optim/rmsprop.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/optim/sgd.py -> build/lib/bitsandbytes/optim\n",
      "copying bitsandbytes/research/__init__.py -> build/lib/bitsandbytes/research\n",
      "copying bitsandbytes/triton/__init__.py -> build/lib/bitsandbytes/triton\n",
      "copying bitsandbytes/triton/dequantize_rowwise.py -> build/lib/bitsandbytes/triton\n",
      "copying bitsandbytes/triton/int8_matmul_mixed_dequanitze.py -> build/lib/bitsandbytes/triton\n",
      "copying bitsandbytes/triton/int8_matmul_rowwise_dequantize.py -> build/lib/bitsandbytes/triton\n",
      "copying bitsandbytes/triton/quantize_columnwise_and_transpose.py -> build/lib/bitsandbytes/triton\n",
      "copying bitsandbytes/triton/quantize_global.py -> build/lib/bitsandbytes/triton\n",
      "copying bitsandbytes/triton/quantize_rowwise.py -> build/lib/bitsandbytes/triton\n",
      "copying bitsandbytes/triton/triton_utils.py -> build/lib/bitsandbytes/triton\n",
      "copying bitsandbytes/research/autograd/__init__.py -> build/lib/bitsandbytes/research/autograd\n",
      "copying bitsandbytes/research/autograd/_functions.py -> build/lib/bitsandbytes/research/autograd\n",
      "copying bitsandbytes/research/nn/__init__.py -> build/lib/bitsandbytes/research/nn\n",
      "copying bitsandbytes/research/nn/modules.py -> build/lib/bitsandbytes/research/nn\n",
      "copying bitsandbytes/libbitsandbytes_hip_nohipblaslt.so -> build/lib/bitsandbytes\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/bitsandbytes\n",
      "copying build/lib/bitsandbytes/utils.py -> build/bdist.linux-x86_64/egg/bitsandbytes\n",
      "creating build/bdist.linux-x86_64/egg/bitsandbytes/autograd\n",
      "copying build/lib/bitsandbytes/autograd/__init__.py -> build/bdist.linux-x86_64/egg/bitsandbytes/autograd\n",
      "copying build/lib/bitsandbytes/autograd/_functions.py -> build/bdist.linux-x86_64/egg/bitsandbytes/autograd\n",
      "creating build/bdist.linux-x86_64/egg/bitsandbytes/cuda_setup\n",
      "copying build/lib/bitsandbytes/cuda_setup/main.py -> build/bdist.linux-x86_64/egg/bitsandbytes/cuda_setup\n",
      "copying build/lib/bitsandbytes/cuda_setup/__init__.py -> build/bdist.linux-x86_64/egg/bitsandbytes/cuda_setup\n",
      "copying build/lib/bitsandbytes/cuda_setup/env_vars.py -> build/bdist.linux-x86_64/egg/bitsandbytes/cuda_setup\n",
      "creating build/bdist.linux-x86_64/egg/bitsandbytes/nn\n",
      "copying build/lib/bitsandbytes/nn/__init__.py -> build/bdist.linux-x86_64/egg/bitsandbytes/nn\n",
      "copying build/lib/bitsandbytes/nn/modules.py -> build/bdist.linux-x86_64/egg/bitsandbytes/nn\n",
      "copying build/lib/bitsandbytes/nn/triton_based_modules.py -> build/bdist.linux-x86_64/egg/bitsandbytes/nn\n",
      "creating build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/adam.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/adamw.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/lamb.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/lars.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/lion.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/sgd.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/__init__.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/adagrad.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/optimizer.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "copying build/lib/bitsandbytes/optim/rmsprop.py -> build/bdist.linux-x86_64/egg/bitsandbytes/optim\n",
      "creating build/bdist.linux-x86_64/egg/bitsandbytes/research\n",
      "creating build/bdist.linux-x86_64/egg/bitsandbytes/research/autograd\n",
      "copying build/lib/bitsandbytes/research/autograd/__init__.py -> build/bdist.linux-x86_64/egg/bitsandbytes/research/autograd\n",
      "copying build/lib/bitsandbytes/research/autograd/_functions.py -> build/bdist.linux-x86_64/egg/bitsandbytes/research/autograd\n",
      "creating build/bdist.linux-x86_64/egg/bitsandbytes/research/nn\n",
      "copying build/lib/bitsandbytes/research/nn/__init__.py -> build/bdist.linux-x86_64/egg/bitsandbytes/research/nn\n",
      "copying build/lib/bitsandbytes/research/nn/modules.py -> build/bdist.linux-x86_64/egg/bitsandbytes/research/nn\n",
      "copying build/lib/bitsandbytes/research/__init__.py -> build/bdist.linux-x86_64/egg/bitsandbytes/research\n",
      "creating build/bdist.linux-x86_64/egg/bitsandbytes/triton\n",
      "copying build/lib/bitsandbytes/triton/__init__.py -> build/bdist.linux-x86_64/egg/bitsandbytes/triton\n",
      "copying build/lib/bitsandbytes/triton/dequantize_rowwise.py -> build/bdist.linux-x86_64/egg/bitsandbytes/triton\n",
      "copying build/lib/bitsandbytes/triton/int8_matmul_mixed_dequanitze.py -> build/bdist.linux-x86_64/egg/bitsandbytes/triton\n",
      "copying build/lib/bitsandbytes/triton/int8_matmul_rowwise_dequantize.py -> build/bdist.linux-x86_64/egg/bitsandbytes/triton\n",
      "copying build/lib/bitsandbytes/triton/quantize_columnwise_and_transpose.py -> build/bdist.linux-x86_64/egg/bitsandbytes/triton\n",
      "copying build/lib/bitsandbytes/triton/quantize_global.py -> build/bdist.linux-x86_64/egg/bitsandbytes/triton\n",
      "copying build/lib/bitsandbytes/triton/quantize_rowwise.py -> build/bdist.linux-x86_64/egg/bitsandbytes/triton\n",
      "copying build/lib/bitsandbytes/triton/triton_utils.py -> build/bdist.linux-x86_64/egg/bitsandbytes/triton\n",
      "copying build/lib/bitsandbytes/__init__.py -> build/bdist.linux-x86_64/egg/bitsandbytes\n",
      "copying build/lib/bitsandbytes/__main__.py -> build/bdist.linux-x86_64/egg/bitsandbytes\n",
      "copying build/lib/bitsandbytes/archive_functional.py -> build/bdist.linux-x86_64/egg/bitsandbytes\n",
      "copying build/lib/bitsandbytes/cextension.py -> build/bdist.linux-x86_64/egg/bitsandbytes\n",
      "copying build/lib/bitsandbytes/functional.py -> build/bdist.linux-x86_64/egg/bitsandbytes\n",
      "copying build/lib/bitsandbytes/libbitsandbytes_hip_nohipblaslt.so -> build/bdist.linux-x86_64/egg/bitsandbytes\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/utils.py to utils.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/autograd/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/autograd/_functions.py to _functions.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/cuda_setup/main.py to main.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/cuda_setup/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/cuda_setup/env_vars.py to env_vars.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/nn/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/nn/modules.py to modules.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/nn/triton_based_modules.py to triton_based_modules.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/adam.py to adam.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/adamw.py to adamw.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/lamb.py to lamb.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/lars.py to lars.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/lion.py to lion.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/sgd.py to sgd.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/adagrad.py to adagrad.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/optimizer.py to optimizer.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/optim/rmsprop.py to rmsprop.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/research/autograd/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/research/autograd/_functions.py to _functions.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/research/nn/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/research/nn/modules.py to modules.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/research/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/triton/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/triton/dequantize_rowwise.py to dequantize_rowwise.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/triton/int8_matmul_mixed_dequanitze.py to int8_matmul_mixed_dequanitze.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/triton/int8_matmul_rowwise_dequantize.py to int8_matmul_rowwise_dequantize.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/triton/quantize_columnwise_and_transpose.py to quantize_columnwise_and_transpose.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/triton/quantize_global.py to quantize_global.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/triton/quantize_rowwise.py to quantize_rowwise.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/triton/triton_utils.py to triton_utils.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/__main__.py to __main__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/archive_functional.py to archive_functional.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/cextension.py to cextension.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/bitsandbytes/functional.py to functional.cpython-310.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying bitsandbytes.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying bitsandbytes.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying bitsandbytes.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying bitsandbytes.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "zip_safe flag not set; analyzing archive contents...\n",
      "bitsandbytes.cuda_setup.__pycache__.main.cpython-310: module references __file__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating 'dist/bitsandbytes-0.39.1-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing bitsandbytes-0.39.1-py3.10.egg\n",
      "removing '/opt/conda/envs/py_3.10/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg' (and everything under it)\n",
      "creating /opt/conda/envs/py_3.10/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg\n",
      "Extracting bitsandbytes-0.39.1-py3.10.egg to /opt/conda/envs/py_3.10/lib/python3.10/site-packages\n",
      "Adding bitsandbytes 0.39.1 to easy-install.pth file\n",
      "\n",
      "Installed /opt/conda/envs/py_3.10/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg\n",
      "Processing dependencies for bitsandbytes==0.39.1\n",
      "Finished processing dependencies for bitsandbytes==0.39.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git clone --recurse https://github.com/ROCmSoftwarePlatform/bitsandbytes\n",
    "cd bitsandbytes\n",
    "git checkout 4c0ca08aa24d622940d9abdcff6090efc85dbc30\n",
    "make hip\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check the bitsandbytes version (0.39.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip list | grep bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/envs/py_3.10/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/libbitsandbytes_hip_nohipblaslt.so\n",
      "CUDA SETUP: Loading binary /opt/conda/envs/py_3.10/lib/python3.10/site-packages/bitsandbytes-0.39.1-py3.10.egg/bitsandbytes/libbitsandbytes_hip_nohipblaslt.so...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configuring the model and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access Meta's official Llama-2 model from Hugging Face after making a request, which can\n",
    "take a couple of days. Instead of waiting, we'll use NousResearch’s Llama-2-7b-chat-hf as our base\n",
    "model (it's the same as the original, but quicker to access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "# Model and tokenizer names\n",
    "base_model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "new_model_name = \"llama-2-7b-enhanced\" #You can give your own name for fine tuned model\n",
    "\n",
    "# Tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\"  \n",
    "\n",
    "# Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have the base model, you can start fine-tuning. We fine-tune our base model for a\n",
    "question-and-answer task using a small data set called\n",
    "[mlabonne/guanaco-llama2-1k](https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k), which\n",
    "is a subset (1,000 samples) of the\n",
    "[timdettmers/openassistant-guanaco](https://huggingface.co/datasets/OpenAssistant/oasst1) data set.\n",
    "This data set is a human-generated, human-annotated, assistant-style conversation corpus that\n",
    "contains 161,443 messages in 35 different languages, annotated with 461,292 quality ratings. This\n",
    "results in over 10,000 fully annotated conversation trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "data_name = \"mlabonne/guanaco-llama2-1k\"\n",
    "training_data = load_dataset(data_name, split=\"train\")\n",
    "# check the data\n",
    "print(training_data.shape)\n",
    "# #11 is a QA sample in English\n",
    "print(training_data[11])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(1000, 1)\n",
    "{'text': '<s>[INST] write me a 1000 words essay about deez nuts. [/INST] The Deez Nuts meme first gained popularity in 2015 on the social media platform Vine. The video featured a young man named Rodney Bullard, who recorded himself asking people if they had heard of a particular rapper. When they responded that they had not, he would respond with the phrase \"Deez Nuts\" and film their reactions. The video quickly went viral, and the phrase became a popular meme. \\n\\nSince then, Deez Nuts has been used in a variety of contexts to interrupt conversations, derail discussions, or simply add humor to a situation. It has been used in internet memes, in popular music, and even in politics. In the 2016 US presidential election, a 15-year-old boy named Brady Olson registered as an independent candidate under the name Deez Nuts. He gained some traction in the polls and even made appearances on national news programs.\\n\\nThe Deez Nuts meme has had a significant impact on popular culture. It has become a recognizable catchphrase that people use to add humor to everyday conversations. The meme has also been used to satirize politics and other serious issues. For example, in 2016, a group of activists in the UK used the phrase \"Deez Nuts for President\" as part of a campaign to encourage young people to vote in the EU referendum. </s><s>[INST] Rewrite the essay in a more casual way. Instead of sounding proffesional, sound like a college student who is forced to write the essay but refuses to do so in the propper way. Use casual words and slang when possible. [/INST] Yo, so you want me to write a 1000-word essay about Deez Nuts? Alright, fine. So, this whole thing started on Vine back in 2015. Some dude named Rodney Bullard made a video where he would ask people if they knew a rapper, and when they said no, he would hit them with the classic line: \"Deez Nuts!\" People loved it, and it became a viral meme.\\n\\nNowadays, Deez Nuts is used for all kinds of stuff. You can throw it out there to interrupt someone or just to be funny. It\\'s all over the internet, in music, and even in politics. In fact, during the 2016 US presidential election, a kid named Brady Olson registered as an independent candidate under the name Deez Nuts. He actually got some attention from the media and made appearances on TV and everything.\\n\\nThe impact of Deez Nuts on our culture is pretty huge. It\\'s become a thing that everyone knows and uses to add some humor to their everyday conversations. Plus, people have used it to make fun of politics and serious issues too. Like, in the UK, some groups of activists used the phrase \"Deez Nuts for President\" to encourage young people to vote in the EU referendum.\\n\\nThere you have it, a thousand words about Deez Nuts in a more casual tone. Can I go back to playing video games now? </s>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from tensorboardX) (1.26.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from tensorboardX) (23.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/conda/envs/py_3.10/lib/python3.10/site-packages (from tensorboardX) (3.20.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## There is a dependency during training\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Start fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set your training parameters, use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Params\n",
    "train_params = TrainingArguments(\n",
    "    output_dir=\"./results_modified\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=50,\n",
    "    logging_steps=50,\n",
    "    learning_rate=4e-5,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with LoRA configuration<a class=\"anchor\" id=\"Training_with_LoRA_configuration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can integrate LoRA into the base model and assess its additional parameters. LoRA essentially adds pairs of rank-decomposition weight matrices (called update matrices) to existing weights, and only trains the newly added weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "# LoRA Config\n",
    "peft_parameters = LoraConfig(\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, peft_parameters)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are only 0.062% parameters added by LoRA, which is a tiny portion of the original model. This is the percentage we'll update through fine-tuning, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 07:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.613500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.391500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.377300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=1.5535581665039062, metrics={'train_runtime': 484.7942, 'train_samples_per_second': 2.063, 'train_steps_per_second': 0.516, 'total_flos': 1.701064079130624e+16, 'train_loss': 1.5535581665039062, 'epoch': 1.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainer with LoRA configration\n",
    "fine_tuning = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=training_data,\n",
    "    peft_config=peft_parameters,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=llama_tokenizer,\n",
    "    args=train_params\n",
    ")\n",
    "\n",
    "# Training\n",
    "fine_tuning.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save your model, run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "fine_tuning.model.save_pretrained(new_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking memory usage during training with LoRA<a class=\"anchor\" id=\"Checking_memory_usage_during_training_with_LoRA\"></a>\n",
    "During training, you can check the memory usage by running the `rocm-smi` command in a terminal.\n",
    "This command produces the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "========================= ROCm System Management Interface =========================\n",
    "=================================== Concise Info ===================================\n",
    "GPU  Temp (DieEdge)  AvgPwr  SCLK     MCLK     Fan  Perf  PwrCap  VRAM%  GPU%  \n",
    "0    52.0c           179.0W  1700Mhz  1600Mhz  0%   auto  300.0W   65%   100%  \n",
    "1    52.0c           171.0W  1650Mhz  1600Mhz  0%   auto  300.0W   66%   100%  \n",
    "====================================================================================\n",
    "=============================== End of ROCm SMI Log ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate a comparison between fine-tuning with and without LoRA, our subsequent phase involves running a thorough fine-tuning process on the base model. This involves updating all parameters within the base model. We then analyze differences in memory usage, training speed, training loss, and other relevant metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training without LoRA configuration<a class=\"anchor\" id=\"Training_without_LoRA_configuration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***To run this section, you need to to restart the kernel an and skip the [Training with LoRA configuration](#Training_with_LoRA_configuration) section.***\n",
    "\n",
    "For a direct comparison between models using the same criteria, we maintain consistent settings (without any alterations) for train_params during the full-parameter fine-tuning process.\n",
    "\n",
    "To check the trainable parameters in your base model, use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainable params: 6738415616 || all params: 6738415616 || trainable%: 100.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a lower lerning Rate for fine tuning\n",
    "train_params.learning_rate = 4e-7\n",
    "print(train_params.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TSsPNqspeFt5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 3:02:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.712300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.487000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.363800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.371100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.368300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=1.4604909362792968, metrics={'train_runtime': 10993.7995, 'train_samples_per_second': 0.091, 'train_steps_per_second': 0.023, 'total_flos': 1.6999849383985152e+16, 'train_loss': 1.4604909362792968, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainer without LoRA configration\n",
    "\n",
    "fine_tuning_full = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=training_data,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=llama_tokenizer,\n",
    "    args=train_params\n",
    ")\n",
    "\n",
    "# Training\n",
    "fine_tuning_full.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking memory usage during training without LoRA<a class=\"anchor\" id=\"Checking_memory_usage_during_training_without_LoRA\"></a>\n",
    "During training, you can check the memory usage by running the `rocm-smi` command in a terminal.\n",
    "This command produces the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "========================= ROCm System Management Interface =========================\n",
    "=================================== Concise Info ===================================\n",
    "GPU  Temp (DieEdge)  AvgPwr  SCLK     MCLK     Fan  Perf  PwrCap  VRAM%  GPU%  \n",
    "0    40.0c           44.0W   800Mhz   1600Mhz  0%   auto  300.0W   100%  89%    \n",
    "1    39.0c           50.0W   1700Mhz  1600Mhz  0%   auto  300.0W   100%  85%    \n",
    "====================================================================================\n",
    "=============================== End of ROCm SMI Log ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Comparison between fine-tuning with LoRA and full-parameter fine-tuning\n",
    "<a class=\"anchor\" id=\"Comparison\"></a>\n",
    "Comparing the results from the [Training with LoRA configuration](#Training_with_LoRA_configuration) and [Training without LoRA configuration](#Training_without_LoRA_configuration) sections, note the following:\n",
    "- Memory usage: \n",
    "    - In the case of full-parameter fine-tuning, there are **6,738,415,616** trainable parameters, leading to significant memory consumption during the training back propagation stage.\n",
    "    - In contrast, LoRA introduces only **4,194,304** trainable parameters, accounting for a mere **0.062%** of the total trainable parameters in full-parameter fine-tuning.\n",
    "    - Monitoring memory usage during training with and without LoRA reveals that fine-tuning with LoRA\n",
    "        uses only **65%** of the memory consumed by full-parameter fine-tuning. This presents an\n",
    "        opportunity to increase batch size and max sequence length, and train on larger data sets using\n",
    "        limited hardware resources.This presents an opportunity to increase batch size, max sequence length, and train on larger datasets within the constraints of limited hardware resources.\n",
    "- Training speed: \n",
    "    - The results demonstrate that full-parameter fine-tuning takes **hours** to complete, while\n",
    "        fine-tuning with LoRA finishes in less than **9 minutes**. Several factors contribute to this\n",
    "        acceleration:\n",
    "    - Several factors contribute to this acceleration:\n",
    "        - Fewer trainable parameters in LoRA translate to fewer derivative calculations and less memory\n",
    "        required to store and update weights.\n",
    "        - Full-parameter fine-tuning is more prone to being memory-bound, where data movement\n",
    "        becomes a bottleneck for training. This is reflected in lower GPU utilization. Although adjusting\n",
    "        training settings can alleviate this, it may require more resources (additional GPUs) and a smaller\n",
    "        batch size.\n",
    "- Accuracy: \n",
    "    - In both training sessions, a notable reduction in training loss was observed. We achieved a closely\n",
    "        aligned training loss for two both approaches: **1.368** for full-parameter fine-tuning and\n",
    "        **1.377** for fine-tuning with LoRA. If you're interested in understanding the impact of LoRA on\n",
    "        fine-tuning performance, refer to\n",
    "        [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test the fine-tuned model with LoRA\n",
    "<a class=\"anchor\" id=\"Test_the_model\"></a>\n",
    "\n",
    "To test your model, run the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "model = PeftModel.from_pretrained(base_model, new_model_name)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading the model to Hugging Face let's you conduct subsequent tests or share your model with\n",
    "others (to proceed with this step, you'll need an active Hugging Face account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 8.19k/9.98G [00:00<33:56:21, 81.7kB/s]\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 336k/9.98G [00:00<1:28:01, 1.89MB/s]  \u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 2.00M/9.98G [00:00<19:39, 8.45MB/s]   \u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 6.23M/9.98G [00:00<07:46, 21.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 12.2M/9.98G [00:00<04:46, 34.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 16.0M/9.98G [00:00<06:27, 25.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 22.8M/9.98G [00:00<04:34, 36.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|          | 22.8M/3.50G [00:00<01:32, 37.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 28.9M/9.98G [00:00<04:07, 40.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 33.2M/9.98G [00:01<05:16, 31.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 39.2M/9.98G [00:01<04:34, 36.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 44.2M/9.98G [00:01<04:12, 39.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   1%|▏         | 52.5M/3.50G [00:01<01:24, 40.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 55.1M/9.98G [00:01<05:00, 33.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 60.1M/9.98G [00:01<04:31, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   2%|▏         | 70.9M/3.50G [00:01<01:19, 43.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 64.5M/9.98G [00:02<05:58, 27.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 71.2M/9.98G [00:02<04:50, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 76.1M/9.98G [00:02<04:25, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 80.5M/9.98G [00:02<05:25, 30.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 93.4M/9.98G [00:02<04:06, 40.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   3%|▎         | 112M/3.50G [00:02<01:21, 41.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 109M/9.98G [00:03<04:00, 41.1MB/s] [A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   4%|▎         | 128M/3.50G [00:03<01:26, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 119M/9.98G [00:03<04:28, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|▏         | 125M/9.98G [00:03<03:58, 41.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|▏         | 135M/9.98G [00:04<04:44, 34.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   1%|▏         | 142M/9.98G [00:04<04:04, 40.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 157M/9.98G [00:04<03:59, 40.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   5%|▌         | 176M/3.50G [00:04<01:43, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 167M/9.98G [00:04<04:44, 34.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 173M/9.98G [00:05<04:04, 40.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 178M/9.98G [00:05<04:50, 33.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 189M/9.98G [00:05<03:53, 41.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   6%|▌         | 213M/3.50G [00:05<01:26, 37.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 199M/9.98G [00:05<04:15, 38.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 205M/9.98G [00:05<03:45, 43.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 210M/9.98G [00:06<04:07, 39.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 221M/9.98G [00:06<03:32, 46.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 226M/9.98G [00:06<04:09, 39.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 237M/9.98G [00:06<03:31, 46.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   7%|▋         | 259M/3.50G [00:06<01:35, 33.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 253M/9.98G [00:07<03:50, 42.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   8%|▊         | 272M/3.50G [00:07<01:40, 32.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 274M/9.98G [00:07<04:03, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 279M/9.98G [00:07<03:48, 42.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 286M/9.98G [00:07<03:26, 46.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 302M/9.98G [00:08<03:37, 44.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   9%|▉         | 309M/3.50G [00:08<01:44, 30.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 311M/9.98G [00:08<04:04, 39.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 318M/9.98G [00:08<03:37, 44.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   9%|▉         | 328M/3.50G [00:08<01:17, 40.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 327M/9.98G [00:08<03:51, 41.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 334M/9.98G [00:09<03:27, 46.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  10%|▉         | 343M/3.50G [00:09<01:19, 39.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 338M/9.98G [00:09<04:56, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 344M/9.98G [00:09<04:25, 36.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▎         | 350M/9.98G [00:09<03:51, 41.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▎         | 355M/9.98G [00:09<04:11, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▎         | 359M/9.98G [00:09<04:07, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▎         | 365M/9.98G [00:09<03:39, 43.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 375M/9.98G [00:10<04:03, 39.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 382M/9.98G [00:10<03:35, 44.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  11%|█         | 391M/3.50G [00:10<01:28, 35.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 386M/9.98G [00:10<05:00, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 391M/9.98G [00:10<04:36, 34.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 398M/9.98G [00:10<03:57, 40.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 407M/9.98G [00:11<04:17, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 414M/9.98G [00:11<03:41, 43.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 423M/9.98G [00:11<04:18, 36.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 430M/9.98G [00:11<03:43, 42.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|█▎        | 439M/3.50G [00:11<01:27, 35.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 445M/9.98G [00:12<03:45, 42.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|█▎        | 452M/3.50G [00:12<01:44, 29.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  13%|█▎        | 456M/3.50G [00:12<01:38, 31.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 461M/9.98G [00:12<04:08, 38.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 466M/9.98G [00:12<05:01, 31.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 472M/9.98G [00:12<04:16, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 477M/9.98G [00:12<03:59, 39.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|█▍        | 482M/3.50G [00:13<01:37, 30.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 481M/9.98G [00:13<05:17, 29.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 495M/9.98G [00:13<03:49, 41.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  14%|█▍        | 500M/3.50G [00:13<01:22, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|█▍        | 508M/3.50G [00:13<01:08, 43.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|█▍        | 513M/3.50G [00:13<01:30, 32.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 503M/9.98G [00:14<07:28, 21.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 508M/9.98G [00:14<06:09, 25.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  15%|█▌        | 535M/3.50G [00:14<01:10, 41.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 525M/9.98G [00:14<04:09, 37.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  16%|█▌        | 549M/3.50G [00:14<01:21, 36.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 542M/9.98G [00:15<04:01, 39.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 547M/9.98G [00:15<04:26, 35.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 551M/9.98G [00:15<04:07, 38.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 557M/9.98G [00:15<03:45, 41.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 562M/9.98G [00:15<04:36, 34.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 567M/9.98G [00:15<04:06, 38.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 573M/9.98G [00:15<03:37, 43.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 578M/9.98G [00:16<04:42, 33.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 589M/9.98G [00:16<03:46, 41.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  17%|█▋        | 608M/3.50G [00:16<01:26, 33.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 594M/9.98G [00:16<04:42, 33.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 605M/9.98G [00:16<03:38, 42.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  18%|█▊        | 629M/3.50G [00:16<01:10, 40.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 616M/9.98G [00:17<03:50, 40.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 621M/9.98G [00:17<03:33, 43.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▋         | 626M/9.98G [00:17<04:12, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▋         | 637M/9.98G [00:17<03:31, 44.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   6%|▋         | 642M/9.98G [00:17<04:53, 31.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 653M/9.98G [00:18<03:43, 41.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  19%|█▉        | 672M/3.50G [00:18<01:31, 30.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 669M/9.98G [00:18<03:37, 42.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  20%|█▉        | 688M/3.50G [00:18<01:18, 35.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 685M/9.98G [00:18<03:24, 45.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 690M/9.98G [00:19<04:05, 37.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 695M/9.98G [00:19<03:53, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 701M/9.98G [00:19<03:27, 44.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 706M/9.98G [00:19<04:30, 34.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 711M/9.98G [00:19<04:02, 38.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 724M/9.98G [00:19<03:54, 39.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 728M/9.98G [00:19<03:51, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 734M/9.98G [00:20<03:33, 43.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 738M/9.98G [00:20<04:05, 37.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 744M/9.98G [00:20<03:46, 40.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 750M/9.98G [00:20<03:20, 46.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  22%|██▏       | 765M/3.50G [00:20<01:07, 40.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 755M/9.98G [00:20<05:27, 28.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 759M/9.98G [00:20<05:15, 29.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 765M/9.98G [00:21<04:18, 35.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 770M/9.98G [00:21<04:52, 31.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 776M/9.98G [00:21<04:05, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 783M/9.98G [00:21<03:33, 43.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 788M/9.98G [00:21<03:43, 41.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 792M/9.98G [00:21<03:40, 41.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 797M/9.98G [00:21<03:29, 43.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 802M/9.98G [00:22<04:45, 32.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 808M/9.98G [00:22<04:06, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 815M/9.98G [00:22<03:33, 42.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  24%|██▍       | 835M/3.50G [00:22<01:09, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  24%|██▍       | 839M/3.50G [00:22<01:08, 38.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 823M/9.98G [00:22<05:23, 28.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 830M/9.98G [00:22<04:21, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 834M/9.98G [00:23<04:50, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 840M/9.98G [00:23<04:13, 36.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 847M/9.98G [00:23<03:35, 42.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  25%|██▍       | 871M/3.50G [00:23<01:06, 39.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▊         | 857M/9.98G [00:23<04:09, 36.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▊         | 863M/9.98G [00:23<03:36, 42.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  25%|██▌       | 887M/3.50G [00:23<01:05, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▊         | 873M/9.98G [00:23<03:57, 38.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 880M/9.98G [00:24<05:03, 30.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 889M/9.98G [00:24<03:59, 38.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 895M/9.98G [00:24<03:31, 43.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  26%|██▌       | 912M/3.50G [00:24<01:31, 28.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 900M/9.98G [00:24<05:18, 28.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 907M/9.98G [00:25<04:29, 33.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  27%|██▋       | 930M/3.50G [00:25<01:09, 36.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 912M/9.98G [00:25<04:48, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 925M/9.98G [00:25<03:29, 43.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 930M/9.98G [00:25<03:49, 39.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 943M/9.98G [00:25<03:12, 47.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 948M/9.98G [00:26<04:10, 36.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 954M/9.98G [00:26<03:43, 40.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  28%|██▊       | 967M/3.50G [00:26<01:19, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 960M/9.98G [00:26<04:42, 31.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 967M/9.98G [00:26<03:50, 39.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 973M/9.98G [00:26<03:25, 43.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 978M/9.98G [00:26<04:02, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 984M/9.98G [00:26<03:44, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 990M/9.98G [00:27<03:20, 44.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 995M/9.98G [00:27<04:15, 35.1MB/s]]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.00G/9.98G [00:27<03:58, 37.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.01G/9.98G [00:27<03:30, 42.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.02G/9.98G [00:27<04:09, 35.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.02G/9.98G [00:27<03:29, 42.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  29%|██▉       | 1.03G/3.50G [00:28<01:27, 28.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.04G/9.98G [00:28<03:49, 38.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  30%|██▉       | 1.04G/3.50G [00:28<01:23, 29.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.04G/9.98G [00:28<04:33, 32.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.05G/9.98G [00:28<03:13, 46.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  30%|███       | 1.06G/3.50G [00:28<01:09, 35.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.06G/9.98G [00:28<04:00, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.08G/9.98G [00:29<03:09, 47.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.09G/9.98G [00:29<03:41, 40.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.09G/9.98G [00:29<03:14, 45.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.10G/9.98G [00:29<03:10, 46.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  31%|███       | 1.09G/3.50G [00:29<01:33, 25.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.11G/9.98G [00:30<04:36, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.11G/9.98G [00:30<04:26, 33.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.12G/9.98G [00:30<04:01, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  32%|███▏      | 1.11G/3.50G [00:30<01:05, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█▏        | 1.13G/9.98G [00:30<04:26, 33.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█▏        | 1.13G/9.98G [00:30<03:49, 38.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  11%|█▏        | 1.14G/9.98G [00:31<04:11, 35.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.15G/9.98G [00:31<03:31, 41.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  32%|███▏      | 1.14G/3.50G [00:31<01:15, 31.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.15G/9.98G [00:31<04:18, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.17G/9.98G [00:31<03:29, 42.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.17G/9.98G [00:31<04:14, 34.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.17G/9.98G [00:32<03:52, 37.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.18G/9.98G [00:32<03:25, 42.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.19G/9.98G [00:32<04:14, 34.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.19G/9.98G [00:32<03:52, 37.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.20G/9.98G [00:32<03:23, 43.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  34%|███▍      | 1.19G/3.50G [00:32<01:07, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.20G/9.98G [00:32<05:33, 26.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.21G/9.98G [00:33<04:54, 29.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.21G/9.98G [00:33<04:08, 35.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  34%|███▍      | 1.21G/3.50G [00:33<00:57, 39.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.22G/9.98G [00:33<03:57, 36.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.23G/9.98G [00:33<03:27, 42.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  35%|███▍      | 1.22G/3.50G [00:33<01:01, 37.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.26G/9.98G [00:34<03:29, 41.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  35%|███▌      | 1.23G/3.50G [00:34<02:04, 18.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.26G/9.98G [00:34<04:45, 30.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.28G/9.98G [00:34<03:20, 43.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  36%|███▌      | 1.25G/3.50G [00:34<01:33, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.28G/9.98G [00:34<04:00, 36.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.29G/9.98G [00:35<03:50, 37.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  36%|███▌      | 1.27G/3.50G [00:35<01:00, 36.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  36%|███▋      | 1.27G/3.50G [00:35<00:58, 38.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.31G/9.98G [00:35<03:33, 40.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  37%|███▋      | 1.28G/3.50G [00:35<01:12, 30.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.32G/9.98G [00:35<03:54, 37.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.33G/9.98G [00:36<03:13, 44.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  37%|███▋      | 1.30G/3.50G [00:36<01:04, 34.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.33G/9.98G [00:36<04:04, 35.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.34G/9.98G [00:36<03:31, 40.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  38%|███▊      | 1.32G/3.50G [00:36<00:54, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  38%|███▊      | 1.32G/3.50G [00:36<00:55, 39.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.34G/9.98G [00:36<05:09, 27.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▎        | 1.35G/9.98G [00:36<04:18, 33.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▎        | 1.36G/9.98G [00:37<03:43, 38.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▎        | 1.36G/9.98G [00:37<04:11, 34.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▎        | 1.37G/9.98G [00:37<03:34, 40.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.37G/9.98G [00:37<03:13, 44.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.38G/9.98G [00:37<03:39, 39.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.38G/9.98G [00:37<03:35, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.39G/9.98G [00:37<03:12, 44.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.40G/9.98G [00:38<04:12, 34.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.40G/9.98G [00:38<03:36, 39.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  40%|███▉      | 1.38G/3.50G [00:38<00:54, 39.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.42G/9.98G [00:38<03:07, 45.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.42G/9.98G [00:38<02:51, 49.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  40%|███▉      | 1.40G/3.50G [00:38<00:57, 36.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.44G/9.98G [00:38<03:03, 46.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  40%|████      | 1.41G/3.50G [00:38<00:56, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.44G/9.98G [00:39<04:01, 35.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.45G/9.98G [00:39<03:16, 43.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  41%|████      | 1.43G/3.50G [00:39<01:15, 27.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  41%|████      | 1.43G/3.50G [00:39<01:12, 28.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.46G/9.98G [00:39<05:06, 27.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.47G/9.98G [00:40<04:16, 33.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  41%|████▏     | 1.45G/3.50G [00:40<01:03, 32.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  42%|████▏     | 1.45G/3.50G [00:40<00:53, 38.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  42%|████▏     | 1.46G/3.50G [00:40<01:06, 30.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.47G/9.98G [00:40<06:56, 20.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.49G/9.98G [00:40<04:21, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.49G/9.98G [00:40<04:49, 29.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.50G/9.98G [00:41<04:22, 32.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.50G/9.98G [00:41<03:42, 38.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.51G/9.98G [00:41<04:22, 32.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.51G/9.98G [00:41<03:42, 38.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.52G/9.98G [00:41<03:25, 41.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  43%|████▎     | 1.51G/3.50G [00:41<00:57, 34.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  43%|████▎     | 1.51G/3.50G [00:41<00:51, 38.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.53G/9.98G [00:42<05:44, 24.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.54G/9.98G [00:42<04:43, 29.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.54G/9.98G [00:42<04:52, 28.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.54G/9.98G [00:42<04:41, 30.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.55G/9.98G [00:42<04:01, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.55G/9.98G [00:42<04:44, 29.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.56G/9.98G [00:43<04:00, 35.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.57G/9.98G [00:43<04:04, 34.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.58G/9.98G [00:43<03:41, 37.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.58G/9.98G [00:43<03:21, 41.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.59G/9.98G [00:43<04:10, 33.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.59G/9.98G [00:43<03:48, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.60G/9.98G [00:44<04:12, 33.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.61G/9.98G [00:44<03:45, 37.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.61G/9.98G [00:44<03:23, 41.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  46%|████▌     | 1.61G/3.50G [00:44<00:41, 45.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  46%|████▋     | 1.62G/3.50G [00:44<00:50, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  46%|████▋     | 1.63G/3.50G [00:44<00:44, 42.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.63G/3.50G [00:45<00:53, 34.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.64G/3.50G [00:45<00:42, 43.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.65G/3.50G [00:45<00:38, 48.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.65G/3.50G [00:45<00:43, 42.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.66G/3.50G [00:45<00:40, 45.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  48%|████▊     | 1.66G/3.50G [00:45<00:44, 41.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.62G/9.98G [00:45<14:04, 9.90MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▋        | 1.63G/9.98G [00:46<07:03, 19.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▋        | 1.64G/9.98G [00:46<06:43, 20.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▋        | 1.65G/9.98G [00:46<04:44, 29.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.65G/9.98G [00:46<04:58, 27.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.66G/9.98G [00:46<04:14, 32.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.66G/9.98G [00:47<03:37, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  49%|████▉     | 1.72G/3.50G [00:47<00:50, 35.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.68G/9.98G [00:47<03:30, 39.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  49%|████▉     | 1.73G/3.50G [00:47<00:52, 33.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  50%|████▉     | 1.74G/3.50G [00:47<00:43, 40.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.69G/9.98G [00:48<03:31, 39.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.70G/9.98G [00:48<03:50, 35.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.71G/9.98G [00:48<03:11, 43.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.71G/9.98G [00:48<03:34, 38.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.72G/9.98G [00:48<03:26, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.73G/9.98G [00:48<03:51, 35.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.74G/9.98G [00:49<03:33, 38.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.75G/9.98G [00:49<03:50, 35.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.76G/9.98G [00:49<03:15, 42.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  51%|█████▏    | 1.80G/3.50G [00:49<01:00, 27.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.77G/9.98G [00:49<03:35, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.77G/9.98G [00:50<03:08, 43.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  52%|█████▏    | 1.81G/3.50G [00:50<00:44, 37.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.78G/9.98G [00:50<03:40, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.79G/9.98G [00:50<03:08, 43.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.79G/9.98G [00:50<03:27, 39.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.80G/9.98G [00:50<03:24, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.81G/9.98G [00:50<03:02, 44.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  53%|█████▎    | 1.85G/3.50G [00:50<00:42, 38.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▊        | 1.87G/9.98G [00:52<02:53, 46.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.88G/9.98G [00:52<03:30, 38.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.89G/9.98G [00:52<03:03, 44.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  53%|█████▎    | 1.86G/3.50G [00:52<02:09, 12.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.90G/9.98G [00:53<03:24, 39.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.90G/9.98G [00:53<02:59, 44.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  54%|█████▎    | 1.88G/3.50G [00:53<01:16, 21.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.91G/9.98G [00:53<03:15, 41.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.92G/9.98G [00:53<02:54, 46.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.92G/9.98G [00:53<02:52, 46.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.93G/9.98G [00:54<02:45, 48.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  54%|█████▍    | 1.91G/3.50G [00:54<00:53, 30.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.94G/9.98G [00:54<03:35, 37.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.95G/9.98G [00:54<03:04, 43.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.96G/9.98G [00:54<03:47, 35.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.96G/9.98G [00:54<03:34, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.97G/9.98G [00:55<03:20, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.98G/9.98G [00:55<03:17, 40.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.98G/9.98G [00:55<02:55, 45.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  56%|█████▌    | 1.95G/3.50G [00:55<00:38, 40.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.99G/9.98G [00:55<04:34, 29.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.99G/9.98G [00:55<04:22, 30.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.00G/9.98G [00:55<03:37, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.00G/9.98G [00:56<04:32, 29.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.01G/9.98G [00:56<03:24, 39.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.02G/9.98G [00:56<04:05, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.02G/9.98G [00:56<03:33, 37.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.03G/9.98G [00:56<03:32, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.04G/9.98G [00:56<03:26, 38.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.05G/9.98G [00:57<03:02, 43.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.05G/9.98G [00:57<03:41, 35.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.06G/9.98G [00:57<03:22, 39.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.06G/9.98G [00:57<03:00, 43.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.07G/9.98G [00:57<03:27, 38.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.07G/9.98G [00:57<03:09, 41.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.08G/9.98G [00:57<02:52, 45.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.08G/9.98G [00:58<03:20, 39.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.09G/9.98G [00:58<03:20, 39.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.09G/9.98G [00:58<03:00, 43.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  59%|█████▉    | 2.06G/3.50G [00:58<00:31, 45.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.10G/9.98G [00:58<04:16, 30.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.10G/9.98G [00:58<03:45, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.12G/9.98G [00:58<03:28, 37.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.12G/9.98G [00:58<03:25, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██▏       | 2.12G/9.98G [00:59<03:04, 42.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██▏       | 2.13G/9.98G [00:59<04:05, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██▏       | 2.14G/9.98G [00:59<03:33, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  21%|██▏       | 2.14G/9.98G [00:59<03:07, 41.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  60%|██████    | 2.12G/3.50G [00:59<00:33, 40.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.15G/9.98G [00:59<03:39, 35.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.16G/9.98G [01:00<03:04, 42.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  61%|██████    | 2.13G/3.50G [01:00<00:30, 45.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.17G/9.98G [01:00<03:52, 33.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.17G/9.98G [01:00<03:14, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.18G/9.98G [01:00<03:36, 36.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.19G/9.98G [01:00<03:03, 42.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  62%|██████▏   | 2.17G/3.50G [01:00<00:32, 40.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.20G/9.98G [01:01<03:27, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.21G/9.98G [01:01<02:57, 43.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.22G/9.98G [01:01<03:20, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.22G/9.98G [01:01<02:53, 44.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.23G/9.98G [01:01<03:51, 33.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.23G/9.98G [01:02<03:35, 35.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.24G/9.98G [01:02<03:05, 41.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.25G/9.98G [01:02<03:13, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.25G/9.98G [01:02<02:50, 45.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.26G/9.98G [01:02<03:47, 33.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.26G/9.98G [01:02<03:30, 36.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.27G/9.98G [01:02<03:03, 42.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.28G/9.98G [01:03<03:16, 39.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.29G/9.98G [01:03<02:49, 45.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.29G/9.98G [01:03<03:17, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.30G/9.98G [01:03<03:14, 39.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.30G/9.98G [01:03<02:52, 44.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.31G/9.98G [01:03<04:04, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.31G/9.98G [01:04<03:41, 34.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.32G/9.98G [01:04<03:12, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.32G/9.98G [01:04<04:07, 31.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.33G/9.98G [01:04<03:31, 36.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.33G/9.98G [01:04<03:01, 42.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  66%|██████▌   | 2.32G/3.50G [01:04<00:28, 40.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.34G/9.98G [01:04<04:32, 28.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.34G/9.98G [01:05<04:23, 29.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▎       | 2.35G/9.98G [01:05<03:59, 31.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▎       | 2.36G/9.98G [01:05<03:19, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▎       | 2.37G/9.98G [01:05<02:53, 43.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.37G/9.98G [01:05<03:23, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.38G/9.98G [01:05<02:57, 42.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.38G/9.98G [01:06<03:24, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.39G/9.98G [01:06<02:53, 43.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.40G/9.98G [01:06<02:33, 49.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  68%|██████▊   | 2.37G/3.50G [01:06<00:30, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.40G/9.98G [01:06<03:26, 36.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.41G/9.98G [01:06<02:58, 42.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  68%|██████▊   | 2.39G/3.50G [01:06<00:26, 42.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.42G/9.98G [01:06<02:48, 44.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.43G/9.98G [01:07<02:34, 48.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▉   | 2.41G/3.50G [01:07<00:27, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▉   | 2.41G/3.50G [01:07<00:24, 44.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.44G/9.98G [01:07<04:08, 30.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.44G/9.98G [01:07<03:32, 35.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▉   | 2.43G/3.50G [01:07<00:23, 45.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.45G/9.98G [01:07<04:46, 26.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.46G/9.98G [01:08<03:51, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.46G/9.98G [01:08<03:18, 37.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.47G/9.98G [01:08<03:26, 36.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.47G/9.98G [01:08<03:06, 40.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.48G/9.98G [01:08<02:47, 44.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  70%|███████   | 2.47G/3.50G [01:08<00:27, 37.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.48G/9.98G [01:08<03:53, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.49G/9.98G [01:09<03:12, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  71%|███████   | 2.48G/3.50G [01:09<00:29, 34.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  71%|███████   | 2.49G/3.50G [01:09<00:27, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.50G/9.98G [01:09<04:32, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.50G/9.98G [01:09<04:19, 28.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.51G/9.98G [01:09<03:33, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.51G/9.98G [01:09<04:12, 29.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.52G/9.98G [01:09<03:20, 37.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.53G/9.98G [01:09<02:55, 42.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.53G/9.98G [01:10<03:55, 31.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.54G/9.98G [01:10<03:19, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  72%|███████▏  | 2.54G/3.50G [01:10<00:25, 37.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.54G/9.98G [01:10<03:44, 33.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.55G/9.98G [01:10<02:54, 42.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.56G/9.98G [01:10<02:38, 46.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.57G/9.98G [01:11<02:38, 46.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  73%|███████▎  | 2.56G/3.50G [01:11<00:28, 32.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.58G/9.98G [01:11<02:45, 44.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.59G/9.98G [01:11<02:26, 50.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.60G/9.98G [01:11<02:59, 41.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.61G/9.98G [01:11<02:58, 41.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.61G/9.98G [01:12<03:54, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.62G/9.98G [01:12<03:27, 35.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▋       | 2.62G/9.98G [01:12<03:02, 40.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▍  | 2.61G/3.50G [01:12<00:23, 38.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▋       | 2.63G/9.98G [01:12<03:29, 35.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▋       | 2.64G/9.98G [01:12<03:04, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▌  | 2.63G/3.50G [01:12<00:20, 42.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▌  | 2.64G/3.50G [01:12<00:18, 46.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▌  | 2.64G/3.50G [01:13<00:24, 35.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▋       | 2.64G/9.98G [01:13<06:13, 19.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.65G/9.98G [01:13<04:18, 28.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.66G/9.98G [01:13<05:16, 23.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.66G/9.98G [01:13<03:57, 30.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.67G/9.98G [01:14<03:20, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.67G/9.98G [01:14<03:29, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.68G/9.98G [01:14<03:19, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.69G/9.98G [01:14<02:54, 41.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.69G/9.98G [01:14<03:47, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.70G/9.98G [01:14<03:27, 35.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.70G/9.98G [01:14<02:56, 41.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.71G/9.98G [01:15<03:18, 36.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.71G/9.98G [01:15<03:02, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.72G/9.98G [01:15<02:42, 44.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  78%|███████▊  | 2.72G/3.50G [01:15<00:20, 38.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  78%|███████▊  | 2.73G/3.50G [01:15<00:19, 39.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.73G/9.98G [01:15<04:39, 26.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.73G/9.98G [01:15<03:44, 32.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  78%|███████▊  | 2.74G/3.50G [01:16<00:21, 35.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.74G/9.98G [01:16<03:57, 30.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.74G/9.98G [01:16<03:15, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.75G/9.98G [01:16<02:53, 41.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.77G/9.98G [01:16<02:36, 45.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  79%|███████▉  | 2.77G/3.50G [01:16<00:33, 21.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  79%|███████▉  | 2.78G/3.50G [01:17<00:28, 25.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  79%|███████▉  | 2.78G/3.50G [01:17<00:21, 32.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.77G/9.98G [01:17<07:02, 17.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  80%|███████▉  | 2.79G/3.50G [01:17<00:23, 30.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.78G/9.98G [01:17<05:03, 23.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  80%|████████  | 2.80G/3.50G [01:17<00:20, 33.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.79G/9.98G [01:17<05:05, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.80G/9.98G [01:18<03:13, 37.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  81%|████████  | 2.82G/3.50G [01:18<00:18, 36.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.81G/9.98G [01:18<03:12, 37.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.82G/9.98G [01:19<06:02, 19.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.82G/9.98G [01:19<05:05, 23.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.83G/9.98G [01:19<04:06, 29.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.83G/9.98G [01:19<04:33, 26.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.84G/9.98G [01:19<03:33, 33.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▊       | 2.85G/9.98G [01:19<03:02, 39.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▊       | 2.85G/9.98G [01:19<03:34, 33.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▊       | 2.86G/9.98G [01:20<03:14, 36.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.87G/9.98G [01:20<03:42, 31.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.88G/9.98G [01:20<03:20, 35.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  82%|████████▏ | 2.89G/3.50G [01:20<00:26, 23.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.89G/9.98G [01:21<03:16, 36.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.89G/9.98G [01:21<02:57, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  83%|████████▎ | 2.90G/3.50G [01:21<00:17, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.90G/9.98G [01:21<03:24, 34.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.91G/9.98G [01:21<03:07, 37.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  83%|████████▎ | 2.92G/3.50G [01:21<00:18, 31.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.93G/9.98G [01:22<02:47, 42.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  84%|████████▎ | 2.93G/3.50G [01:22<00:19, 29.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.93G/9.98G [01:22<03:30, 33.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.94G/9.98G [01:22<02:51, 41.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.95G/9.98G [01:22<04:05, 28.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.95G/9.98G [01:22<03:30, 33.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.96G/9.98G [01:23<03:27, 33.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.97G/9.98G [01:23<02:56, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.97G/9.98G [01:23<02:39, 43.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.98G/9.98G [01:23<03:21, 34.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.98G/9.98G [01:23<03:08, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 2.99G/9.98G [01:24<03:21, 34.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.00G/9.98G [01:24<03:05, 37.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.01G/9.98G [01:24<02:44, 42.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  86%|████████▌ | 3.01G/3.50G [01:24<00:11, 43.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.01G/9.98G [01:24<03:43, 31.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.03G/9.98G [01:24<03:02, 38.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.03G/9.98G [01:24<02:57, 39.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.04G/9.98G [01:25<02:39, 43.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.05G/9.98G [01:25<02:42, 42.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  87%|████████▋ | 3.04G/3.50G [01:25<00:17, 26.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.06G/9.98G [01:25<03:30, 32.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.06G/9.98G [01:25<03:15, 35.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.07G/9.98G [01:25<02:49, 40.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  88%|████████▊ | 3.06G/3.50G [01:26<00:11, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.08G/9.98G [01:26<03:05, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.09G/9.98G [01:26<02:43, 42.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  88%|████████▊ | 3.08G/3.50G [01:26<00:11, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  88%|████████▊ | 3.09G/3.50G [01:26<00:09, 43.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  88%|████████▊ | 3.09G/3.50G [01:26<00:11, 34.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.09G/9.98G [01:27<06:42, 17.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.09G/9.98G [01:27<06:06, 18.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.10G/9.98G [01:27<04:56, 23.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  89%|████████▉ | 3.12G/3.50G [01:27<00:08, 45.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  89%|████████▉ | 3.12G/3.50G [01:27<00:09, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.10G/9.98G [01:27<05:47, 19.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.12G/9.98G [01:27<03:38, 31.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  90%|████████▉ | 3.14G/3.50G [01:27<00:09, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███▏      | 3.13G/9.98G [01:28<03:21, 34.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███▏      | 3.13G/9.98G [01:28<02:51, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  31%|███▏      | 3.14G/9.98G [01:28<03:20, 34.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.15G/9.98G [01:28<03:12, 35.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.16G/9.98G [01:29<03:01, 37.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.17G/9.98G [01:29<02:39, 42.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  91%|█████████ | 3.18G/3.50G [01:29<00:09, 33.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.17G/9.98G [01:29<03:30, 32.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.17G/9.98G [01:29<03:16, 34.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.19G/9.98G [01:29<03:10, 35.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.19G/9.98G [01:29<02:53, 39.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.20G/9.98G [01:30<02:36, 43.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.20G/9.98G [01:30<03:04, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.21G/9.98G [01:30<02:48, 40.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.21G/9.98G [01:30<02:34, 43.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.23G/9.98G [01:30<02:41, 41.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.23G/9.98G [01:31<03:26, 32.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.24G/9.98G [01:31<03:12, 35.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.25G/9.98G [01:31<02:46, 40.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.25G/9.98G [01:31<03:09, 35.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.25G/9.98G [01:31<02:57, 37.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.27G/9.98G [01:31<03:09, 35.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.27G/9.98G [01:32<02:48, 39.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.28G/9.98G [01:32<02:31, 44.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.28G/9.98G [01:32<03:03, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.29G/9.98G [01:32<02:57, 37.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.29G/9.98G [01:32<02:36, 42.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.30G/9.98G [01:32<03:25, 32.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.31G/9.98G [01:32<02:43, 40.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.31G/9.98G [01:33<03:10, 35.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.32G/9.98G [01:33<02:47, 39.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.33G/9.98G [01:33<02:32, 43.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.33G/9.98G [01:33<03:10, 34.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.34G/9.98G [01:33<03:02, 36.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▎      | 3.35G/9.98G [01:34<03:19, 33.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▎      | 3.35G/9.98G [01:34<03:00, 36.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  96%|█████████▌| 3.35G/3.50G [01:34<00:03, 41.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▎      | 3.36G/9.98G [01:34<02:58, 37.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.37G/9.98G [01:34<02:48, 39.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.37G/9.98G [01:34<02:29, 44.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.38G/9.98G [01:34<03:05, 35.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.38G/9.98G [01:34<02:52, 38.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.39G/9.98G [01:35<02:31, 43.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.39G/9.98G [01:35<03:43, 29.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.40G/9.98G [01:35<03:34, 30.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.40G/9.98G [01:35<02:58, 36.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.42G/9.98G [01:35<02:56, 37.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.42G/9.98G [01:35<02:34, 42.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  98%|█████████▊| 3.42G/3.50G [01:35<00:02, 36.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.43G/9.98G [01:36<03:05, 35.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.43G/9.98G [01:36<02:51, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.44G/9.98G [01:36<02:30, 43.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.45G/9.98G [01:36<03:00, 36.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.46G/9.98G [01:37<03:44, 29.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.46G/9.98G [01:37<02:58, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.47G/9.98G [01:37<02:34, 42.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  99%|█████████▊| 3.46G/3.50G [01:37<00:01, 24.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.47G/9.98G [01:37<03:31, 30.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.49G/9.98G [01:37<02:48, 38.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:  99%|█████████▉| 3.47G/3.50G [01:37<00:00, 33.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.49G/9.98G [01:38<03:17, 32.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▌      | 3.51G/9.98G [01:38<02:40, 40.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▌      | 3.51G/9.98G [01:38<02:32, 42.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00002-of-00002.bin: 100%|██████████| 3.50G/3.50G [01:38<00:00, 35.4MB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|██████████| 9.98G/9.98G [04:26<00:00, 37.4MB/s]\n",
      "\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [04:26<00:00, 133.49s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/superbigtree/llama-2-7b-enhanced/commit/cd267caccfaa60711403ff5f44173801ea493c25', commit_message='Upload tokenizer', commit_description='', oid='cd267caccfaa60711403ff5f44173801ea493c25', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "#You need to use your Hugging Face Access Tokens\n",
    "login(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "#Push the model to Hugging Face. This takes minutes and time depends the model size and your network speed.\n",
    "model.push_to_hub(new_model_name, use_temp_dir=False)\n",
    "tokenizer.push_to_hub(new_model_name, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have a test with the base model (original) and the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What do you think is the most important part of building an AI chatbot? [/INST]  There are several important aspects to consider when building an AI chatbot, but here are some of the most critical elements:\n",
      "\n",
      "1. Natural Language Processing (NLP): A chatbot's ability to understand and interpret human language is crucial for effective communication. NLP is the foundation of any chatbot, and it involves training the AI model to recognize patterns in language, interpret meaning, and generate responses.\n",
      "2. Conversational Flow: A chatbot's conversational flow refers to the way it interacts with users. A well-designed conversational flow should be intuitive, easy to follow, and adaptable to different user scenarios. This involves creating a dialogue flowchart that guides the conversation and ensures the chatbot responds appropriately to user inputs.\n",
      "3. Domain Knowledge: A chat\n"
     ]
    }
   ],
   "source": [
    "# Generate Text using base model\n",
    "query = \"What do you think is the most important part of building an AI chatbot?\"\n",
    "text_gen = pipeline(task=\"text-generation\", model=base_model_name, tokenizer=llama_tokenizer, max_length=200)\n",
    "output = text_gen(f\"<s>[INST] {query} [/INST]\")\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What do you think is the most important part of building an AI chatbot? [/INST] The most important part of building an AI chatbot is to ensure that it is able to understand and respond to user input in a way that is both accurate and natural-sounding. This requires a combination of natural language processing (NLP) capabilities and a well-designed conversational flow.\n",
      "\n",
      "Here are some key factors to consider when building an AI chatbot:\n",
      "\n",
      "1. Natural Language Processing (NLP): The chatbot must be able to understand and interpret user input, including both text and voice commands. This requires a robust NLP engine that can handle a wide range of language and dialects.\n",
      "2. Conversational Flow: The chatbot must be able to respond to user input in a way that is both natural and intuitive. This requires a well-designed conversational flow that can handle a wide range\n"
     ]
    }
   ],
   "source": [
    "# Generate Text using fine-tuned model\n",
    "query = \"What do you think is the most important part of building an AI chatbot?\"\n",
    "text_gen = pipeline(task=\"text-generation\", model=new_model_name, tokenizer=llama_tokenizer, max_length=200)\n",
    "output = text_gen(f\"<s>[INST] {query} [/INST]\")\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe the outputs of the two models based on a given query. These outputs exhibit slight\n",
    "differences due to the fine-tuning process altering the model weights."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "015f9b82124945e8b79a13af21c52de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0264db8d79184285a118306184efe1b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "03702decb174454097d5d5f26348f556": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "063b924e85124cea833c7252e224d0fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0797e998f8b14a14a350f56a427a4e02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0aa60d16278c4b76ba182bbf8ddad535": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c698f2e4106466d88273d1a16f780a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ca2da9af74f4d9c987fea1efc11afa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cd2a480289c4482aef2f7fe2c21897e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d32a5ba1e7f4c37ae67b958816ab2df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8127feff017a48c6b9bdc2af65c608bd",
      "placeholder": "​",
      "style": "IPY_MODEL_e0ceb6baa46044bf97e8a7b3451cb8aa",
      "value": " 21.0/21.0 [00:00&lt;00:00, 802B/s]"
     }
    },
    "0ded4610262c47ef81b2089ada679fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b6569407bfc3412eb141c8b100f138b0",
       "IPY_MODEL_17641b27f7c04737b5befeb62bfccb0e",
       "IPY_MODEL_8f4eacc355794b9fbed81481a4b5d157"
      ],
      "layout": "IPY_MODEL_a2b1318732c049d3ae51d2ffd54ed90a"
     }
    },
    "0ec21f912a794b3b825435f6ca47e5d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b805d71a3355469394c5fc448c8ed7a9",
      "placeholder": "​",
      "style": "IPY_MODEL_9c413412d51a4dd1a3582a5683292cf7",
      "value": "(…)at-hf/resolve/main/tokenizer_config.json: 100%"
     }
    },
    "0f368c62e605462caaaa5bf62f101d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0f51b6d6cfeb41e2ae93f0de2f170dea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11ce416d972745bb92d1aef8e1ebe7d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12fe184cbc13435589be8592d0bfe153": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66868196fc504f1b8b8ca3faec6728b7",
      "placeholder": "​",
      "style": "IPY_MODEL_11ce416d972745bb92d1aef8e1ebe7d6",
      "value": "Downloading data: 100%"
     }
    },
    "137210657b484ab8bd716a35a41bbaf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "140d3a6a12d547f8b8b1054c893e043c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfc4288fcb8148cda1e32808e0b58e58",
      "placeholder": "​",
      "style": "IPY_MODEL_1997bc0437134b10bc4330c31be91f64",
      "value": " 583/583 [00:00&lt;00:00, 32.4kB/s]"
     }
    },
    "167dbc01fac0413f8e58a977e1b65511": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16eb2b5be79f48fe9e2d6abb511aafd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17641b27f7c04737b5befeb62bfccb0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_589571b792a548f8b30ca89eb0a15254",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2da5164cb3db4e2dbd4ef33c5070cc74",
      "value": 1000
     }
    },
    "18fa9875e8e041b8a4d87451a180cc8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1997bc0437134b10bc4330c31be91f64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a0ed89decbf4a5bb31ffceb9a533162": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a46566a85244758b5ddc475804770b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5aadb90188b4409abc2a4f696ed00e2",
       "IPY_MODEL_606836d101824ca4abb5d79b3cd10222",
       "IPY_MODEL_a4e7af56c0d84b80bb639e66c7e62aea"
      ],
      "layout": "IPY_MODEL_f079c623618f4ad6acbbe0addeff1131"
     }
    },
    "1abf4087085745a78deab4ce71b37d2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2659a987f0d441148cebb9299c06696a",
      "placeholder": "​",
      "style": "IPY_MODEL_c70dc129f9e54168838d2b0e3db7f8b8",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "1f7097edd387439eb0be1f67f870e8c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_063b924e85124cea833c7252e224d0fa",
      "placeholder": "​",
      "style": "IPY_MODEL_c5b45bb439ea4b28886446b3e93fea54",
      "value": " 1.02k/1.02k [00:00&lt;00:00, 35.3kB/s]"
     }
    },
    "20b229d2cbdb4bedb1557728091cd58d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21295c14fc21481d98bf68702bc81d5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_562622e3658840f789ff2bee7f91071d",
      "max": 966693,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_daa039c82b594fa098313289fb82f482",
      "value": 966693
     }
    },
    "21d0c5de9c7d4c82aec0ca4e1e576118": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "224c4749eced49fea746f5a7bfef6c01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7746fc65466447048e4d789b4c85e157",
       "IPY_MODEL_a046f7cd60d84064926284d1882d170f",
       "IPY_MODEL_d65de52bd3194bbc923df459a7c00f10"
      ],
      "layout": "IPY_MODEL_de59392d1a6348408661e0d35ca92e0d"
     }
    },
    "252e568ce7ff48b2b64a4ed9a8de8505": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54c0d0564910483389714dfdde74b073",
      "placeholder": "​",
      "style": "IPY_MODEL_0797e998f8b14a14a350f56a427a4e02",
      "value": "Extracting data files: 100%"
     }
    },
    "2659a987f0d441148cebb9299c06696a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "274cf470dd5c444dac069484ce9dbfa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28f64d3dd455490fad4ba41d438242fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2975d63c84104c16a7530ae6f18da5a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2da5164cb3db4e2dbd4ef33c5070cc74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "308440e165e14e89921674d288b12da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ec21f912a794b3b825435f6ca47e5d6",
       "IPY_MODEL_66bad46ef4314943bc860bef657c30a7",
       "IPY_MODEL_5b1203544aff45f8920b654ab6ced501"
      ],
      "layout": "IPY_MODEL_3b3deeac6b504f9cb71e2a6df10a1743"
     }
    },
    "349e4436e0c74e5cbf612481fccf656f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "387445fdb18f43e29250c70e83abbbee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b2a542eb32584d5086c2ca9f971366a7",
       "IPY_MODEL_5c1ac4a9c18b4384bb54abadc417d7c7",
       "IPY_MODEL_948de27481f3479c90c45f3a8c24cfd3"
      ],
      "layout": "IPY_MODEL_669234400d9546dd9fed5104b3f1e494"
     }
    },
    "3b1df755d2d346f5a506e8748b1728ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b3deeac6b504f9cb71e2a6df10a1743": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "401af53ae73243dbbff2d18d95553eb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "44837d0de76e4f91995edeb0c2d5f9d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45bdc4da322c495d93d81508e0a1e84d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "465f260d7309434a8b08d8b65bb6c0ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c24d81e1e9f49869660981ea869eb76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "516c18ad3ea34d819b986d0140045a17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51b0a257d6424d05800cf4c3c7b49330": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52520ed93807403abaf107457aca0a12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "53afe8e66cf14a03bc6196ae9c8764d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "54c0d0564910483389714dfdde74b073": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "562622e3658840f789ff2bee7f91071d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "589571b792a548f8b30ca89eb0a15254": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59387ae1b4574aca93adfb244b8bbfb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f78d52cfb243489798228dc32459ab0e",
      "placeholder": "​",
      "style": "IPY_MODEL_137210657b484ab8bd716a35a41bbaf9",
      "value": " 1/1 [00:00&lt;00:00, 50.25it/s]"
     }
    },
    "5a69788f9aba431b849fede41c47fddc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ac1b86720c64269a60af8bf1ff68b17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7fb0cf900534cde91f7a13a0b4dfc80",
      "max": 1017,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f368c62e605462caaaa5bf62f101d65",
      "value": 1017
     }
    },
    "5b1203544aff45f8920b654ab6ced501": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_754d813185fc46cfa27bd70b81f9fe4b",
      "placeholder": "​",
      "style": "IPY_MODEL_f38191b2cc634084828ad627f7f2181d",
      "value": " 746/746 [00:00&lt;00:00, 34.1kB/s]"
     }
    },
    "5c1ac4a9c18b4384bb54abadc417d7c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0635cedaa0247ea8ced2e9dcbd718ad",
      "max": 9976576152,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e246b4bfda34527a280fc956e461eb5",
      "value": 2107637760
     }
    },
    "5c31ee4894b84ae581776b58d45f4833": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "606836d101824ca4abb5d79b3cd10222": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18fa9875e8e041b8a4d87451a180cc8f",
      "max": 499723,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f36df856bf4a490b82f81ba72d5704e6",
      "value": 499723
     }
    },
    "63291353d1bc45bc8cca60c0f1baf714": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66868196fc504f1b8b8ca3faec6728b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "669234400d9546dd9fed5104b3f1e494": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66bad46ef4314943bc860bef657c30a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94f3746fcb8c436ba89feca229bbd233",
      "max": 746,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c31ee4894b84ae581776b58d45f4833",
      "value": 746
     }
    },
    "69dfa7d0adea4dd999145fbcfb71b514": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eddea9bd3fa848ee9bd32389c4daf38b",
      "placeholder": "​",
      "style": "IPY_MODEL_45bdc4da322c495d93d81508e0a1e84d",
      "value": " 1/1 [00:00&lt;00:00,  2.66it/s]"
     }
    },
    "6b06657b141d497e83022c658746d73c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc18750352de43ce994fb7012656a639",
       "IPY_MODEL_b40748bdeb61483eba0be421dae1d2e8",
       "IPY_MODEL_0d32a5ba1e7f4c37ae67b958816ab2df"
      ],
      "layout": "IPY_MODEL_7df834a2b10c4401a3249725c3f09f30"
     }
    },
    "6b382ca560e7428e8364a830e1319ad4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cf666d9c994a434e8c77f79e7a0f3323",
       "IPY_MODEL_84447e0b31dc4113b4b817dcf2ee9f67",
       "IPY_MODEL_140d3a6a12d547f8b8b1054c893e043c"
      ],
      "layout": "IPY_MODEL_c3baed418303436688de0a6cb5a52d63"
     }
    },
    "70f9a67d10714b659e60634183f25806": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71e2bb31cb3f48a8a30442bb09723d84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "754d813185fc46cfa27bd70b81f9fe4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7746fc65466447048e4d789b4c85e157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a55ea6f7bc3a4b898426184bd0446b14",
      "placeholder": "​",
      "style": "IPY_MODEL_70f9a67d10714b659e60634183f25806",
      "value": "(…)2-7b-chat-hf/resolve/main/tokenizer.json: 100%"
     }
    },
    "7df834a2b10c4401a3249725c3f09f30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e2884068fcb4f079cf6e73585b02499": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8127feff017a48c6b9bdc2af65c608bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8325867f479c47708ddf372bff8d8018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84447e0b31dc4113b4b817dcf2ee9f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c24d81e1e9f49869660981ea869eb76",
      "max": 583,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52520ed93807403abaf107457aca0a12",
      "value": 583
     }
    },
    "84871c45c7c6454b90787f93dd3dad75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89ed48c1c91244ef84e911d444baded2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a671b35cc464f7f9f6e8f6e566696b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e800365af154512a13be0295290d7df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f23b87ed81bf41b983f37e18c91679c6",
      "max": 435,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51b0a257d6424d05800cf4c3c7b49330",
      "value": 435
     }
    },
    "8f4eacc355794b9fbed81481a4b5d157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ca2da9af74f4d9c987fea1efc11afa3",
      "placeholder": "​",
      "style": "IPY_MODEL_cd4dbd1fc99948c98ad203f5d73906c6",
      "value": " 1000/1000 [00:00&lt;00:00, 16246.85 examples/s]"
     }
    },
    "948de27481f3479c90c45f3a8c24cfd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84871c45c7c6454b90787f93dd3dad75",
      "placeholder": "​",
      "style": "IPY_MODEL_e49acf47a30b4c7e986f06ece43c4da7",
      "value": " 2.11G/9.98G [00:20&lt;01:08, 115MB/s]"
     }
    },
    "94f3746fcb8c436ba89feca229bbd233": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96b01c2de67b4c238dbdc37cf7e9fcbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_252e568ce7ff48b2b64a4ed9a8de8505",
       "IPY_MODEL_f0af116311c24cd7afc1960a9fdd2d15",
       "IPY_MODEL_59387ae1b4574aca93adfb244b8bbfb3"
      ],
      "layout": "IPY_MODEL_b2ddf9fc0a2b44eeaf4887f64e8bd404"
     }
    },
    "9b0df252064e4ecc9cc21fc3fc025feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e95faa6d3c234f6a97e16f26b02e2a61",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_349e4436e0c74e5cbf612481fccf656f",
      "value": 1
     }
    },
    "9c413412d51a4dd1a3582a5683292cf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e246b4bfda34527a280fc956e461eb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a046f7cd60d84064926284d1882d170f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2975d63c84104c16a7530ae6f18da5a4",
      "max": 1842764,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_53afe8e66cf14a03bc6196ae9c8764d6",
      "value": 1842764
     }
    },
    "a0a9ea7bd00e4ceeadde14b045bd2107": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2b1318732c049d3ae51d2ffd54ed90a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4e7af56c0d84b80bb639e66c7e62aea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_465f260d7309434a8b08d8b65bb6c0ec",
      "placeholder": "​",
      "style": "IPY_MODEL_c05028a5c9cd43c4943a2a575d8c86f5",
      "value": " 500k/500k [00:00&lt;00:00, 20.8MB/s]"
     }
    },
    "a55ea6f7bc3a4b898426184bd0446b14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5aadb90188b4409abc2a4f696ed00e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fda766d1d1554802b8f4b5b462cac147",
      "placeholder": "​",
      "style": "IPY_MODEL_c0ba6b263ba14caa9cc12d02a93ffca2",
      "value": "tokenizer.model: 100%"
     }
    },
    "a6ee66e3e8e74d649fe78c93a12c300a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6f6c6961c8a4bf9b8a60c3f02229f62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7fb0cf900534cde91f7a13a0b4dfc80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a93039c13b0c4df4966f0535e45b6ec5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2a542eb32584d5086c2ca9f971366a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6f6c6961c8a4bf9b8a60c3f02229f62",
      "placeholder": "​",
      "style": "IPY_MODEL_03702decb174454097d5d5f26348f556",
      "value": "model-00001-of-00002.safetensors:  21%"
     }
    },
    "b2ddf9fc0a2b44eeaf4887f64e8bd404": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b40748bdeb61483eba0be421dae1d2e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28f64d3dd455490fad4ba41d438242fb",
      "max": 21,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0264db8d79184285a118306184efe1b1",
      "value": 21
     }
    },
    "b430039c90f94bbcb17dc693afe95ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16eb2b5be79f48fe9e2d6abb511aafd1",
      "placeholder": "​",
      "style": "IPY_MODEL_5a69788f9aba431b849fede41c47fddc",
      "value": " 435/435 [00:00&lt;00:00, 17.8kB/s]"
     }
    },
    "b6569407bfc3412eb141c8b100f138b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c698f2e4106466d88273d1a16f780a2",
      "placeholder": "​",
      "style": "IPY_MODEL_a6ee66e3e8e74d649fe78c93a12c300a",
      "value": "Generating train split: 100%"
     }
    },
    "b797e152f0aa4a03bd64d72a3f1c4c6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e516cb67448243ff9886cdc212103444",
       "IPY_MODEL_fad36ca902a0446faa407627683f4cfa",
       "IPY_MODEL_1abf4087085745a78deab4ce71b37d2c"
      ],
      "layout": "IPY_MODEL_de68290071344484bc0ec2c64ae1679e"
     }
    },
    "b805d71a3355469394c5fc448c8ed7a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdcbd936342b4f8d96515a03c11f09db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf0e4a22190b43e9aead2e19a960c13a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f51b6d6cfeb41e2ae93f0de2f170dea",
      "placeholder": "​",
      "style": "IPY_MODEL_274cf470dd5c444dac069484ce9dbfa8",
      "value": " 967k/967k [00:00&lt;00:00, 2.79MB/s]"
     }
    },
    "c05028a5c9cd43c4943a2a575d8c86f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0635cedaa0247ea8ced2e9dcbd718ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0ba6b263ba14caa9cc12d02a93ffca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c13b4e605eeb4e6b8a2bcd6401c50bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2d5f998bbc5470282f597b4c2955580",
       "IPY_MODEL_9b0df252064e4ecc9cc21fc3fc025feb",
       "IPY_MODEL_69dfa7d0adea4dd999145fbcfb71b514"
      ],
      "layout": "IPY_MODEL_7e2884068fcb4f079cf6e73585b02499"
     }
    },
    "c3baed418303436688de0a6cb5a52d63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b45bb439ea4b28886446b3e93fea54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c70dc129f9e54168838d2b0e3db7f8b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8cd672dc18f46aaa7ab860a80a49fe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_da78cd15a10e425492599154791ce901",
       "IPY_MODEL_8e800365af154512a13be0295290d7df",
       "IPY_MODEL_b430039c90f94bbcb17dc693afe95ca7"
      ],
      "layout": "IPY_MODEL_0cd2a480289c4482aef2f7fe2c21897e"
     }
    },
    "cad8776b2ab74f5aac4dfd67cfa4731b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e16ddfd54b6a409ca2554ad19457d8a0",
       "IPY_MODEL_5ac1b86720c64269a60af8bf1ff68b17",
       "IPY_MODEL_1f7097edd387439eb0be1f67f870e8c0"
      ],
      "layout": "IPY_MODEL_0aa60d16278c4b76ba182bbf8ddad535"
     }
    },
    "cc18750352de43ce994fb7012656a639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71e2bb31cb3f48a8a30442bb09723d84",
      "placeholder": "​",
      "style": "IPY_MODEL_1a0ed89decbf4a5bb31ffceb9a533162",
      "value": "(…)b-chat-hf/resolve/main/added_tokens.json: 100%"
     }
    },
    "cd4dbd1fc99948c98ad203f5d73906c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf666d9c994a434e8c77f79e7a0f3323": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fefcf449d2aa492481ca851e2c7dc971",
      "placeholder": "​",
      "style": "IPY_MODEL_f5c502046b1a46c5be05ec2e983eea24",
      "value": "(…)ma-2-7b-chat-hf/resolve/main/config.json: 100%"
     }
    },
    "d2d5f998bbc5470282f597b4c2955580": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdcbd936342b4f8d96515a03c11f09db",
      "placeholder": "​",
      "style": "IPY_MODEL_44837d0de76e4f91995edeb0c2d5f9d9",
      "value": "Downloading data files: 100%"
     }
    },
    "d323df4a4aee41b7a5b7772f98e504d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d65de52bd3194bbc923df459a7c00f10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89ed48c1c91244ef84e911d444baded2",
      "placeholder": "​",
      "style": "IPY_MODEL_015f9b82124945e8b79a13af21c52de4",
      "value": " 1.84M/1.84M [00:00&lt;00:00, 14.0MB/s]"
     }
    },
    "d7ba178aa44e4e8ba36f65e7d1fba4ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fbcc9800c323443d8e3fd86dfa94092e",
       "IPY_MODEL_e4f3dc1964a34da09bafc7f5ec5c4908",
       "IPY_MODEL_e1b18ae7360a40bd9c10596ece94e805"
      ],
      "layout": "IPY_MODEL_df9e2057afc848d698e34b37199aeb54"
     }
    },
    "da78cd15a10e425492599154791ce901": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d323df4a4aee41b7a5b7772f98e504d9",
      "placeholder": "​",
      "style": "IPY_MODEL_516c18ad3ea34d819b986d0140045a17",
      "value": "(…)-hf/resolve/main/special_tokens_map.json: 100%"
     }
    },
    "daa039c82b594fa098313289fb82f482": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de59392d1a6348408661e0d35ca92e0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de68290071344484bc0ec2c64ae1679e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df9e2057afc848d698e34b37199aeb54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfc4288fcb8148cda1e32808e0b58e58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0ceb6baa46044bf97e8a7b3451cb8aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e16ddfd54b6a409ca2554ad19457d8a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b1df755d2d346f5a506e8748b1728ed",
      "placeholder": "​",
      "style": "IPY_MODEL_167dbc01fac0413f8e58a977e1b65511",
      "value": "Downloading readme: 100%"
     }
    },
    "e1b18ae7360a40bd9c10596ece94e805": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0a9ea7bd00e4ceeadde14b045bd2107",
      "placeholder": "​",
      "style": "IPY_MODEL_f5293e4f58ba4bffa53fe2e70eb52c39",
      "value": " 26.8k/26.8k [00:00&lt;00:00, 923kB/s]"
     }
    },
    "e49acf47a30b4c7e986f06ece43c4da7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4b1929c9c8d44a1aae87879fb9db254": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4f3dc1964a34da09bafc7f5ec5c4908": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21d0c5de9c7d4c82aec0ca4e1e576118",
      "max": 26788,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a671b35cc464f7f9f6e8f6e566696b1",
      "value": 26788
     }
    },
    "e516cb67448243ff9886cdc212103444": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffa73637452545e5a9f0ed3d560705f0",
      "placeholder": "​",
      "style": "IPY_MODEL_8325867f479c47708ddf372bff8d8018",
      "value": "Downloading shards:   0%"
     }
    },
    "e95faa6d3c234f6a97e16f26b02e2a61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eddea9bd3fa848ee9bd32389c4daf38b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f079c623618f4ad6acbbe0addeff1131": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0af116311c24cd7afc1960a9fdd2d15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4b1929c9c8d44a1aae87879fb9db254",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fcf0ec3df90145be90a5b91feaaa20d0",
      "value": 1
     }
    },
    "f23b87ed81bf41b983f37e18c91679c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f36df856bf4a490b82f81ba72d5704e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f38191b2cc634084828ad627f7f2181d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5293e4f58ba4bffa53fe2e70eb52c39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5c502046b1a46c5be05ec2e983eea24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f635d975567d4015a8a1b88d84f50fd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f78d52cfb243489798228dc32459ab0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fad36ca902a0446faa407627683f4cfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f635d975567d4015a8a1b88d84f50fd1",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_401af53ae73243dbbff2d18d95553eb3",
      "value": 0
     }
    },
    "fbcc9800c323443d8e3fd86dfa94092e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a93039c13b0c4df4966f0535e45b6ec5",
      "placeholder": "​",
      "style": "IPY_MODEL_20b229d2cbdb4bedb1557728091cd58d",
      "value": "(…)esolve/main/model.safetensors.index.json: 100%"
     }
    },
    "fbf218564e4041718986ec4a92832a14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12fe184cbc13435589be8592d0bfe153",
       "IPY_MODEL_21295c14fc21481d98bf68702bc81d5b",
       "IPY_MODEL_bf0e4a22190b43e9aead2e19a960c13a"
      ],
      "layout": "IPY_MODEL_63291353d1bc45bc8cca60c0f1baf714"
     }
    },
    "fcf0ec3df90145be90a5b91feaaa20d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fda766d1d1554802b8f4b5b462cac147": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fefcf449d2aa492481ca851e2c7dc971": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffa73637452545e5a9f0ed3d560705f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
