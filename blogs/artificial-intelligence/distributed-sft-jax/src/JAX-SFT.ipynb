{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154417ef-ae25-47b6-9645-6294f66872e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install flax\n",
    "!pip install git+https://github.com/deepmind/optax.git\n",
    "!pip install evaluate\n",
    "!pip install ipywidgets\n",
    "!pip install black isort #jupyter notebook code formatter; optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0c5f6629-af28-4c6c-aeab-f4be7c0d862c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import chain\n",
    "from typing import Callable\n",
    "\n",
    "import evaluate\n",
    "import flax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from flax import traverse_util\n",
    "from flax.training import train_state\n",
    "from flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\n",
    "from ipywidgets import IntProgress as IProgress\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    FlaxAutoModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b74254cb-49ed-4931-89da-f8244164de0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[gpu(id=0),\n",
       " gpu(id=1),\n",
       " gpu(id=2),\n",
       " gpu(id=3),\n",
       " gpu(id=4),\n",
       " gpu(id=5),\n",
       " gpu(id=6),\n",
       " gpu(id=7)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c9f3d430-11a5-4c75-8242-eacbb1dae995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = \"qqp\"\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "per_device_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e1314-f2e5-4d4a-86ae-a35161febdf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset(\"glue\", task)\n",
    "metric = evaluate.load(\"glue\", task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "169043b5-b787-4a55-a2ca-5cf94b89c263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "24400f10-0528-494e-8d25-252e2d1acd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    texts = (examples[\"question1\"], examples[\"question2\"])\n",
    "    processed = tokenizer(*texts, padding=\"max_length\", max_length=128, truncation=True)\n",
    "    processed[\"labels\"] = examples[\"label\"]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3295145d-815b-4f2c-9a73-28d952aa1112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original training dataset is: (363846, 4)\n",
      "Shape of the current training dataset is: (36384, 4)\n",
      "Shape of the current evaluation dataset is: (36385, 4)\n"
     ]
    }
   ],
   "source": [
    "# Details about how to handle and process huggingface dataset:\n",
    "# https://huggingface.co/docs/datasets/process\n",
    "data = raw_dataset[\"train\"].shuffle(seed=0)\n",
    "train_data = data.select(list(range(int(data.shape[0] * 0.1))))\n",
    "eval_data = data.select(list(range(int(data.shape[0] * 0.1), int(data.shape[0] * 0.2))))\n",
    "print(f\"Shape of the original training dataset is: {data.shape}\")\n",
    "print(f\"Shape of the current training dataset is: {train_data.shape}\")\n",
    "print(f\"Shape of the current evaluation dataset is: {eval_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4245a547-4914-489a-87da-85f3afcfa5ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afee37464d64b6fa2b52477ff61f2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_data.map(\n",
    "    preprocess_function, batched=True, remove_columns=train_data.column_names\n",
    ")\n",
    "eval_dataset = eval_data.map(\n",
    "    preprocess_function, batched=True, remove_columns=eval_data.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b87db36d-6f5a-4f93-b8c6-5060bba5982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 1327, 1132, 1103, 2182, 1115, 1127, 1309...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 1327, 1132, 1103, 4583, 2489, 1827, 1111...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2009, 1132, 1199, 22413, 1603, 15376, 13...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [101, 1327, 1132, 1103, 2182, 1115, 1127, 1309...   \n",
       "1  [101, 1327, 1132, 1103, 4583, 2489, 1827, 1111...   \n",
       "2  [101, 2009, 1132, 1199, 22413, 1603, 15376, 13...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                      attention_mask  labels  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_dataset[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2b01a74f-b55f-4fb3-96cb-36e99530d56d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'transform', 'dense', 'bias')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: {('classifier', 'kernel'), ('classifier', 'bias'), ('bert', 'pooler', 'dense', 'kernel'), ('bert', 'pooler', 'dense', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 2\n",
    "seed = 0\n",
    "config = AutoConfig.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, config=config, seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "98c8dcaf-68db-4b15-a3c5-80037be9943e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_train_epochs = 6\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d35d9c8b-5a29-46b0-9f55-1811484b901e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall batch size (both for training and eval) is 512\n"
     ]
    }
   ],
   "source": [
    "total_batch_size = per_device_batch_size * jax.local_device_count()\n",
    "print(\"The overall batch size (both for training and eval) is\", total_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "dc1b0b5c-a632-478d-995e-2bf0c573f63c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_train_steps = len(train_dataset) // total_batch_size * num_train_epochs\n",
    "\n",
    "learning_rate_function = optax.linear_schedule(\n",
    "    init_value=learning_rate, end_value=0, transition_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "da9883bb-ddaa-41b5-8a24-0672e0a718d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    logits_function: Callable = flax.struct.field(pytree_node=False)\n",
    "    loss_function: Callable = flax.struct.field(pytree_node=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9d1e15c6-33db-449c-88d4-7f0ed887f7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a decay_mask_fn function to make sure that weight decay is not applied to any bias or LayerNorm weights\n",
    "# as it may not improve model performance and even be harmful.\n",
    "def decay_mask_fn(params):\n",
    "    flat_params = traverse_util.flatten_dict(params)\n",
    "    flat_mask = {\n",
    "        path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\"))\n",
    "        for path in flat_params\n",
    "    }\n",
    "    return traverse_util.unflatten_dict(flat_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f0375ba5-94ef-4d4f-8f5a-5b5c968006a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Adam optimizer with weight decay\n",
    "def adamw(weight_decay):\n",
    "    return optax.adamw(\n",
    "        learning_rate=learning_rate_function,\n",
    "        b1=0.9,\n",
    "        b2=0.999,\n",
    "        eps=1e-6,\n",
    "        weight_decay=weight_decay,\n",
    "        mask=decay_mask_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "11fbfdf0-cbf8-4c88-a07e-a765c6463378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_function(logits, labels):\n",
    "    xentropy = optax.softmax_cross_entropy(\n",
    "        logits, onehot(labels, num_classes=num_labels)\n",
    "    )\n",
    "    return jnp.mean(xentropy)\n",
    "\n",
    "\n",
    "def eval_function(logits):\n",
    "    return logits.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cf825d38-b380-43c6-b3d1-3625975c1d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the TrainState\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.__call__,\n",
    "    params=model.params,\n",
    "    tx=adamw(weight_decay=0.01),\n",
    "    logits_function=eval_function,\n",
    "    loss_function=loss_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "27f9bdd3-e0f5-42f2-a38f-661cdfbbaf81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(state, batch, dropout_rng):\n",
    "    targets = batch.pop(\"labels\")\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "\n",
    "    def loss_function(params):\n",
    "        logits = state.apply_fn(\n",
    "            **batch, params=params, dropout_rng=dropout_rng, train=True\n",
    "        )[0]\n",
    "        loss = state.loss_function(logits, targets)\n",
    "        return loss\n",
    "\n",
    "    grad_function = jax.value_and_grad(loss_function)\n",
    "    loss, grad = grad_function(state.params)\n",
    "    grad = jax.lax.pmean(grad, \"batch\")\n",
    "    new_state = state.apply_gradients(grads=grad)\n",
    "    metrics = jax.lax.pmean(\n",
    "        {\"loss\": loss, \"learning_rate\": learning_rate_function(state.step)},\n",
    "        axis_name=\"batch\",\n",
    "    )\n",
    "    return new_state, metrics, new_dropout_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "dbb2cb0f-f8ce-461e-a2a0-2e1239af798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n",
    "    return state.logits_function(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a754de7e-ae19-4865-aa6b-096bd72a3722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))\n",
    "parallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")\n",
    "state = flax.jax_utils.replicate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d46d6692-bf10-4d42-8287-9e5cbdd0c5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def glue_train_data_loader(rng, dataset, batch_size):\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "    perms = jax.random.permutation(rng, len(dataset))\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    for perm in perms:\n",
    "        batch = dataset[perm]\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        batch = shard(batch)\n",
    "\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2e4020d1-0c2c-4448-bae1-e1119cce8295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def glue_eval_data_loader(dataset, batch_size):\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i * batch_size : (i + 1) * batch_size]\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        batch = shard(batch)\n",
    "\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "631c6897-855e-47e2-ab31-9562de493ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(seed)\n",
    "dropout_rngs = jax.random.split(rng, jax.local_device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8be56bb2-4d61-407c-9aee-fe1972f650ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdef831d3563410482b1e70bfc6af856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch ...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0bd14cdd9749558c9b1db164ac6d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6 | Train loss: 0.475 | Eval accuracy: 0.799, f1: 0.762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d711be9ee9aa4d20bd0b7fe96de09a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/6 | Train loss: 0.369 | Eval accuracy: 0.834, f1: 0.789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd72d4871cc54597a1b0f0693c63b431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/6 | Train loss: 0.299 | Eval accuracy: 0.846, f1: 0.797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2792ea221b8c4e30ad752684473eef87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/6 | Train loss: 0.239 | Eval accuracy: 0.846, f1: 0.806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b86ec6d117466bacabbc9c5e344d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/6 | Train loss: 0.252 | Eval accuracy: 0.849, f1: 0.802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1076bdfd559f44f58ef586dfb4c06c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 | Train loss: 0.212 | Eval accuracy: 0.849, f1: 0.805\n"
     ]
    }
   ],
   "source": [
    "for i, epoch in enumerate(\n",
    "    tqdm(range(1, num_train_epochs + 1), desc=f\"Epoch ...\", position=0, leave=True)\n",
    "):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "    # train\n",
    "    with tqdm(\n",
    "        total=len(train_dataset) // total_batch_size, desc=\"Training...\", leave=True\n",
    "    ) as progress_bar_train:\n",
    "        for batch in glue_train_data_loader(input_rng, train_dataset, total_batch_size):\n",
    "            state, train_metrics, dropout_rngs = parallel_train_step(\n",
    "                state, batch, dropout_rngs\n",
    "            )\n",
    "            progress_bar_train.update(1)\n",
    "\n",
    "    # evaluate\n",
    "    with tqdm(\n",
    "        total=len(eval_dataset) // total_batch_size, desc=\"Evaluating...\", leave=False\n",
    "    ) as progress_bar_eval:\n",
    "        for batch in glue_eval_data_loader(eval_dataset, total_batch_size):\n",
    "            labels = batch.pop(\"labels\")\n",
    "            predictions = parallel_eval_step(state, batch)\n",
    "            metric.add_batch(\n",
    "                predictions=list(chain(*predictions)), references=list(chain(*labels))\n",
    "            )\n",
    "            progress_bar_eval.update(1)\n",
    "\n",
    "    eval_metric = metric.compute()\n",
    "\n",
    "    loss = round(flax.jax_utils.unreplicate(train_metrics)[\"loss\"].item(), 3)\n",
    "    eval_score1 = round(list(eval_metric.values())[0], 3)\n",
    "    metric_name1 = list(eval_metric.keys())[0]\n",
    "    eval_score2 = round(list(eval_metric.values())[1], 3)\n",
    "    metric_name2 = list(eval_metric.keys())[1]\n",
    "    print(\n",
    "        f\"{i+1}/{num_train_epochs} | Train loss: {loss} | Eval {metric_name1}: {eval_score1}, {metric_name2}: {eval_score2}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924b62e-4d98-4375-87e0-32422b605f87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a class=\"anchor\" id=\"appendix\"></a>Appendix: using JAX device mesh to achieve parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a5639f6f-ec47-4956-9659-440a05c9e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import mesh_utils\n",
    "from jax.sharding import Mesh, NamedSharding\n",
    "from jax.sharding import PartitionSpec as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8c936e75-c8ee-4e92-b4a5-4ecf9e289442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'transform', 'dense', 'bias')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: {('classifier', 'kernel'), ('classifier', 'bias'), ('bert', 'pooler', 'dense', 'kernel'), ('bert', 'pooler', 'dense', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, config=config, seed=seed\n",
    ")\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.__call__,\n",
    "    params=model.params,\n",
    "    tx=adamw(weight_decay=0.01),\n",
    "    logits_function=eval_function,\n",
    "    loss_function=loss_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "088bbc0c-efad-4676-b7f9-b3910d7c89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch, dropout_rng):\n",
    "    targets = batch.pop(\"labels\")\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "\n",
    "    def loss_function(params):\n",
    "        logits = state.apply_fn(\n",
    "            **batch, params=params, dropout_rng=dropout_rng, train=True\n",
    "        )[0]\n",
    "        loss = state.loss_function(logits, targets)\n",
    "        return loss\n",
    "\n",
    "    grad_function = jax.value_and_grad(loss_function)\n",
    "    loss, grad = grad_function(state.params)\n",
    "    new_state = state.apply_gradients(grads=grad)\n",
    "    metrics = {\"loss\": loss, \"learning_rate\": learning_rate_function(state.step)}\n",
    "    return new_state, metrics, new_dropout_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b155055e-4436-4664-94e7-98e5d6d8b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n",
    "    return state.logits_function(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2c100bd4-0bbf-479b-b1f3-9bb0730a42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_devices = len(jax.local_devices())\n",
    "devices = mesh_utils.create_device_mesh((num_devices,))\n",
    "\n",
    "# Data will be split along the batch axis\n",
    "data_mesh = Mesh(devices, axis_names=(\"batch\",))  # naming axes of the mesh\n",
    "data_sharding = NamedSharding(\n",
    "    data_mesh,\n",
    "    P(\n",
    "        \"batch\",\n",
    "    ),\n",
    ")  # naming axes of the sharded partition\n",
    "\n",
    "\n",
    "def glue_train_data_loader(rng, dataset, batch_size):\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "    perms = jax.random.permutation(rng, len(dataset))\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    for perm in perms:\n",
    "        batch = dataset[perm]\n",
    "        batch = {\n",
    "            k: jax.device_put(jnp.array(v), data_sharding) for k, v in batch.items()\n",
    "        }\n",
    "\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def glue_eval_data_loader(dataset, batch_size):\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i * batch_size : (i + 1) * batch_size]\n",
    "        batch = {\n",
    "            k: jax.device_put(jnp.array(v), data_sharding) for k, v in batch.items()\n",
    "        }\n",
    "\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3a436de0-2ff6-4524-b94c-cfb145bdb7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate the model and optimizer variable on all devices\n",
    "def get_replicated_train_state(devices, state):\n",
    "    # All variables will be replicated on all devices\n",
    "    var_mesh = Mesh(devices, axis_names=(\"_\"))\n",
    "    # In NamedSharding, axes not mentioned are replicated (all axes here)\n",
    "    var_replication = NamedSharding(var_mesh, P())\n",
    "\n",
    "    # Apply the distribution settings to the model variables\n",
    "    state = jax.device_put(state, var_replication)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "state = get_replicated_train_state(devices, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "97a23fa9-015a-4da7-93ab-0b8bf2abdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(seed)\n",
    "dropout_rng = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5f3dcac7-df58-432d-8ba3-e5ef2665213f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cb1cda4a8d4011ba0f9bf0f4e4bc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch ...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81b503fe2914760b40d3cb5c311b983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6 | Train loss: 0.469 | Eval accuracy: 0.796, f1: 0.759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14da64be00d54cbd9e4332562d244531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/6 | Train loss: 0.376 | Eval accuracy: 0.833, f1: 0.788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c404619d414d9b93a32d7b65b06b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/6 | Train loss: 0.296 | Eval accuracy: 0.844, f1: 0.795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f603ae4e125945559e93fd720267006f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/6 | Train loss: 0.267 | Eval accuracy: 0.846, f1: 0.805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b7c83dbef7412db0ed6d6ea5ca937f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/6 | Train loss: 0.263 | Eval accuracy: 0.848, f1: 0.804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcef7893fdc4ef1a22e3809345d5db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 | Train loss: 0.222 | Eval accuracy: 0.849, f1: 0.805\n"
     ]
    }
   ],
   "source": [
    "for i, epoch in enumerate(\n",
    "    tqdm(range(1, num_train_epochs + 1), desc=f\"Epoch ...\", position=0, leave=True)\n",
    "):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "\n",
    "    # train\n",
    "    with tqdm(\n",
    "        total=len(train_dataset) // total_batch_size, desc=\"Training...\", leave=True\n",
    "    ) as progress_bar_train:\n",
    "        for batch in glue_train_data_loader(input_rng, train_dataset, total_batch_size):\n",
    "            state, train_metrics, dropout_rng = train_step(state, batch, dropout_rng)\n",
    "            progress_bar_train.update(1)\n",
    "\n",
    "    # evaluate\n",
    "    with tqdm(\n",
    "        total=len(eval_dataset) // total_batch_size, desc=\"Evaluating...\", leave=False\n",
    "    ) as progress_bar_eval:\n",
    "        for batch in glue_eval_data_loader(eval_dataset, total_batch_size):\n",
    "            labels = batch.pop(\"labels\")\n",
    "            predictions = eval_step(state, batch)\n",
    "            metric.add_batch(predictions=list(predictions), references=list(labels))\n",
    "            progress_bar_eval.update(1)\n",
    "\n",
    "    eval_metric = metric.compute()\n",
    "\n",
    "    loss = round(train_metrics[\"loss\"].item(), 3)\n",
    "    eval_score1 = round(list(eval_metric.values())[0], 3)\n",
    "    metric_name1 = list(eval_metric.keys())[0]\n",
    "    eval_score2 = round(list(eval_metric.values())[1], 3)\n",
    "    metric_name2 = list(eval_metric.keys())[1]\n",
    "    print(\n",
    "        f\"{i+1}/{num_train_epochs} | Train loss: {loss} | Eval {metric_name1}: {eval_score1}, {metric_name2}: {eval_score2}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
