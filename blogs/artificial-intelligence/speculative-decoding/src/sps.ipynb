{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907ff287-da6f-4cf7-b769-9d73b08bee8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████| 46/46 [00:27<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(30)\n",
    "\n",
    "draft_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\", device_map='auto',torch_dtype=torch.float16)\n",
    "draft_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neox-20b\", device_map='auto',torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64d8197-4600-4e31-94b4-9cc8d28762a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device.type=='cuda', draft_model.device.type=='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c13a715-44c8-4d03-8fad-66e03e286ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Difference between a gasoline and hybrid vehicles is\"\n",
    "K=4\n",
    "N=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed98b1a-6635-4d34-a943-6aa9ffe2b464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between a gasoline and hybrid vehicles is that the gasoline vehicle uses a spark plug to ignite the fuel, while the hybrid vehicle uses a battery to ignite the fuel.\n",
      "\n",
      "The battery is charged by the engine, and the engine is\n",
      "Time taken is 3.85893177986145s\n"
     ]
    }
   ],
   "source": [
    "############## Autoregressive sampling test ##############\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inp = inputs['input_ids'].to('cuda')\n",
    "start = time.time()\n",
    "while(inp.shape[-1]<N):\n",
    "    o = model(inp)\n",
    "    o = torch.softmax(o.logits,-1)\n",
    "    o = torch.argmax(o,-1)[0,-1]\n",
    "    inp = torch.cat((inp, torch.tensor([[o]],device='cuda')),-1)\n",
    "end=time.time()\n",
    "print(tokenizer.decode(inp[0]))\n",
    "print(f'Time taken is {end-start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942bc50c-5042-4ca7-a026-2642ef2baa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[28813,  1945,  1022,   257, 21408,   290, 14554,  5672,   318]],\n",
      "       device='cuda:0')\n",
      "K: 8\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that\n",
      "\n",
      "K: 9\n",
      "K: 10\n",
      "K: 11\n",
      "K: 12\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has\n",
      "\n",
      "K: 13\n",
      "K: 14\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel\n",
      "\n",
      "K: 15\n",
      "K: 16\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that\n",
      "\n",
      "K: 17\n",
      "K: 18\n",
      "K: 19\n",
      "K: 20\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that is filled with gasoline.\n",
      "\n",
      "K: 22\n",
      "K: 23\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that is filled with gasoline. The hybrid\n",
      "\n",
      "K: 24\n",
      "K: 25\n",
      "K: 26\n",
      "K: 27\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that is filled with gasoline. The hybrid vehicle has a fuel tank\n",
      "\n",
      "K: 29\n",
      "K: 30\n",
      "K: 31\n",
      "K: 32\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that is filled with gasoline. The hybrid vehicle has a fuel tank that is filled with a\n",
      "\n",
      "K: 34\n",
      "K: 35\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that is filled with gasoline. The hybrid vehicle has a fuel tank that is filled with a fuel that\n",
      "\n",
      "K: 36\n",
      "K: 37\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that is filled with gasoline. The hybrid vehicle has a fuel tank that is filled with a fuel that is a\n",
      "\n",
      "K: 38\n",
      "K: 39\n",
      "K: 40\n",
      "K: 41\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that is filled with gasoline. The hybrid vehicle has a fuel tank that is filled with a fuel that is a mixture of gasoline and electricity\n",
      "\n",
      "K: 43\n",
      "K: 44\n",
      "K: 45\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that is filled with gasoline. The hybrid vehicle has a fuel tank that is filled with a fuel that is a mixture of gasoline and electricity. The electricity\n",
      "\n",
      "K: 46\n",
      "K: 47\n",
      "torch.Size([49])\n",
      "After verification: Difference between a gasoline and hybrid vehicles is that the gasoline vehicle has a fuel tank that is filled with gasoline. The hybrid vehicle has a fuel tank that is filled with a fuel that is a mixture of gasoline and electricity. The electricity is generated battery\n",
      "\n",
      "Time taken is 2.8490023612976074s\n"
     ]
    }
   ],
   "source": [
    "# def sample(model, draft_model, tokenizer, draft_tokenizer, prompt):\n",
    "inputs = draft_tokenizer(prompt, return_tensors=\"pt\")\n",
    "inp = inputs['input_ids'].to('cuda')\n",
    "print(inp)\n",
    "start = time.time()\n",
    "while(inp.shape[-1]<N):\n",
    "    global_inp = [inp[0]]\n",
    "    global_o=[]\n",
    "    # global_tok=[]\n",
    "    for i in range(K):\n",
    "        o = draft_model(inp)#attn_mask)#,inputs['attention_mask'])\n",
    "        o['logits'] = torch.softmax(o['logits'],-1)\n",
    "        new_token = torch.argmax(o['logits'][0,-1])\n",
    "        inp = torch.cat((inp,torch.tensor([[new_token]],device='cuda')),-1)\n",
    "        global_inp.append(inp[0])\n",
    "        global_o.append((new_token,o.logits[0,-1,new_token]))\n",
    "        # print(draft_tokenizer.decode(new_token), new_token, o.logits[0,-1,new_token])\n",
    "    # print('Draft output: ',global_tok)\n",
    "\n",
    "    ########## VERIFY INPUTS FOR TARGET MODEL #########################\n",
    "    # print(\"Inputs for the target model are:\")\n",
    "    # for i in range(len(global_inp)):\n",
    "    #     print(draft_tokenizer.decode(global_inp[i], ignore_special_tokens=True))\n",
    "    \n",
    "    target_inp=[]\n",
    "    for i in global_inp:\n",
    "        target_inp.append(torch.tensor(tokenizer(draft_tokenizer.decode(i)).input_ids))\n",
    "    first_tok_idx = target_inp[0].shape[0]\n",
    "    target_inp_padded = torch.nn.utils.rnn.pad_sequence(target_inp,batch_first=True,padding_value=0)\n",
    "    \n",
    "    ########## VERIFY INPUTS FOR TARGET MODEL AFTER TOKENIZING & PADDING #########################\n",
    "    # for i in range(len(global_inp)):\n",
    "    #     print(tokenizer.decode(target_inp_padded[i], ignore_special_tokens=True))\n",
    "\n",
    "    target_output = model(target_inp_padded.to('cuda'))#, attention_mask=torch.where(target_inp_padded>0,1,0))\n",
    "    target_output.logits = torch.softmax(target_output.logits,-1)\n",
    "\n",
    "    ########## PRINT SERIALIZED OUTPUTS FROM TARGET MODEL #########################\n",
    "    # out = torch.argmax(target_output.logits,-1)\n",
    "    # out_decode = [tokenizer.decode(out[i][first_tok_idx+i-1]) for i in range(K+1)]\n",
    "    # print('Target output: ',out_decode)\n",
    "    \n",
    "    all_accepted=True\n",
    "    inp = global_inp[0] #Preparing draft model input for next Speculative Sampling\n",
    "    for i in range(K):\n",
    "        print(f'K: {first_tok_idx+i-1}')\n",
    "        token_idx, prob_d = global_o[i] #token index and probability from draft prediction\n",
    "        # probability from target prediction for the same token\n",
    "        prob_t = target_output.logits[i,first_tok_idx+i-1,tokenizer(draft_tokenizer.decode(token_idx)).input_ids[0]]\n",
    "\n",
    "        # Accepted token\n",
    "        if np.random.random() < min(1,prob_t/prob_d):\n",
    "        # if prob_t/prob_d>=1:\n",
    "            # print(f'Accepted {first_tok_idx+i-1} token: ', draft_tokenizer.decode(token_idx), token_idx)\n",
    "            inp = torch.cat((inp,torch.tensor([token_idx],device='cuda')))\n",
    "        \n",
    "        # Modified Rejected token\n",
    "        else:\n",
    "            token_idx = torch.argmax(target_output.logits[i][first_tok_idx+i-1])\n",
    "            # print(f'Replaced  {first_tok_idx+i-1} token: ', tokenizer.decode(token_idx), token_idx)\n",
    "            draft_token_idx = draft_tokenizer([tokenizer.decode(token_idx)]).input_ids[0]\n",
    "            inp = torch.cat((inp,torch.tensor(draft_token_idx,device='cuda')))\n",
    "            all_accepted = False\n",
    "            break\n",
    "            \n",
    "        if inp.shape[-1]==N-1:\n",
    "            print(inp.shape)\n",
    "            break\n",
    "            \n",
    "    # If all accepted then add extra token from target prediction\n",
    "    if all_accepted:\n",
    "        #print('All tokens are accepted, adding extra token')\n",
    "        token_idx = torch.argmax(target_output.logits[-1,first_tok_idx+K-1])\n",
    "        draft_token_idx = draft_tokenizer([tokenizer.decode(token_idx)]).input_ids[0]\n",
    "        prob_t = torch.tensor(draft_token_idx,device='cuda')\n",
    "        inp = torch.cat((inp,prob_t))\n",
    "\n",
    "    print(f'After verification: {draft_tokenizer.decode(inp)}\\n')\n",
    "    inp = inp.unsqueeze(0) #batched input\n",
    "end = time.time()\n",
    "print(f'Time taken is {end-start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed251ea-9acf-4410-b795-4df244d0f93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3541593541593542"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.858/2.849"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9764bb-bb30-4d2d-9d48-5bcf3a0e92a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between a gasoline and hybrid vehicles is that the gasoline vehicle uses a spark plug to ignite the fuel, while the hybrid vehicle uses a battery to power the electric motor.\n",
      "\n",
      "The battery is charged by the engine, which is why the\n",
      "Time taken is 1.913191556930542s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "o = model.generate(inputs['input_ids'].to('cuda'), max_length=N)\n",
    "end=time.time()\n",
    "print(tokenizer.decode(o[0]))\n",
    "print(f'Time taken is {end-start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e86002-b866-4246-85cb-cbc1271ee202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
