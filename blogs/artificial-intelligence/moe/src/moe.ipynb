{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005dc2fc-3cbb-40fd-a6c3-4e18a723e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81785e5-804d-480b-91ff-cfa8e8381cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de920f03-ef7e-4ef0-aacd-1a83dd316ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"mistralai/Mixtral-8x22B-Instruct-v0.1\"\n",
    "pipe = pipeline(\"text-generation\", model=model_path, torch_dtype=torch.bfloat16, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a poem about artificial intelligence becoming conscious in the style of Shakespeare.\"\n",
    "prompt_template=f'''[INST] {prompt} [/INST]'''\n",
    "outputs = pipe(prompt_template, max_new_tokens=512, do_sample=True,     \n",
    "                         temperature=0.8,\n",
    "                         top_k=20,\n",
    "                         top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e30443-4f27-4691-9f47-f3d589d5bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Create a python function that when given two strings word1 and word2 it returns the minimum number of operations required to convert word1 to word2. Only three operations are permitted on each word: Insert a character, Delete a character, Replace a character.\"\n",
    "prompt_template=f'''[INST] {prompt} [/INST]'''\n",
    "outputs = pipe(prompt_template, max_new_tokens=512, do_sample=True,     \n",
    "                         temperature=0.8,\n",
    "                         top_k=20,\n",
    "                         top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29f472-b57c-4641-a290-4dc201fa7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me some jokes about semiconductors.\"\n",
    "prompt_template=f'''[INST] {prompt} [/INST]'''\n",
    "\n",
    "outputs = pipe(prompt_template, max_new_tokens=128, do_sample=True,     \n",
    "temperature=0.8,\n",
    "top_k=20,\n",
    "top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a295c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Please translate the following sentence into English:  Nel mezzo del cammin di nostra vita, mi ritrovai per una selva oscura, ch√© la diritta via era smarrita.\"\n",
    "prompt_template=f'''[INST] {prompt} [/INST]'''\n",
    "\n",
    "outputs = pipe(prompt_template, max_new_tokens=128, do_sample=True,     \n",
    "temperature=0.8,\n",
    "top_k=20,\n",
    "top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
